{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "training = pd.read_csv(r\"../../data/Des_SA/imdb.csv\", encoding=\"utf8\")\n",
    "\n",
    "\n",
    "#remove nonASCIICharacters\n",
    "training[\"text\"] = training.apply(lambda x: \"\".join([i for i in x[\"text\"] if ord(i) <= 127]), axis=1)\n",
    "training\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(s):\n",
    "    match s:\n",
    "        case \"positive\":\n",
    "            return 1\n",
    "        case \"negative\":\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[\"sentiment\"] = training.apply(lambda x: to_class(x[\"sentiment\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training[\"text_tb_pol\"] = training.apply(lambda x: TextBlob(x[\"text\"]).polarity, axis=1)\n",
    "training[\"text_tb_sub\"] = training.apply(lambda x: TextBlob(x[\"text\"]).subjectivity, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "training[\"text_vader_scores\"] = training.apply(lambda x: analyzer.polarity_scores(x[\"text\"]), axis=1)\n",
    "training[\"text_vader_comp\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"compound\"], axis=1)\n",
    "training[\"text_vader_neg\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neg\"], axis=1)\n",
    "training[\"text_vader_neu\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neu\"], axis=1)\n",
    "training[\"text_vader_pos\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"pos\"], axis=1)\n",
    "training = training.drop([\"text_vader_scores\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>text_vader_comp</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023433</td>\n",
       "      <td>0.490369</td>\n",
       "      <td>-0.9916</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109722</td>\n",
       "      <td>0.559343</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354008</td>\n",
       "      <td>0.658730</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.057813</td>\n",
       "      <td>0.454167</td>\n",
       "      <td>-0.9213</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217952</td>\n",
       "      <td>0.452916</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.394425</td>\n",
       "      <td>0.522897</td>\n",
       "      <td>0.9886</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.276190</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>-0.6837</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056984</td>\n",
       "      <td>0.395538</td>\n",
       "      <td>-0.9734</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048663</td>\n",
       "      <td>0.447034</td>\n",
       "      <td>-0.8657</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.637692</td>\n",
       "      <td>0.6975</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment  \\\n",
       "0      One of the other reviewers has mentioned that ...          1   \n",
       "1      A wonderful little production. <br /><br />The...          1   \n",
       "2      I thought this was a wonderful way to spend ti...          1   \n",
       "3      Basically there's a family where a little boy ...          0   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "...                                                  ...        ...   \n",
       "49995  I thought this movie did a down right good job...          1   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0   \n",
       "49997  I am a Catholic taught in parochial elementary...          0   \n",
       "49998  I'm going to have to disagree with the previou...          0   \n",
       "49999  No one expects the Star Trek movies to be high...          0   \n",
       "\n",
       "       text_tb_pol  text_tb_sub  text_vader_comp  text_vader_neg  \\\n",
       "0         0.023433     0.490369          -0.9916           0.179   \n",
       "1         0.109722     0.559343           0.9670           0.052   \n",
       "2         0.354008     0.658730           0.9519           0.114   \n",
       "3        -0.057813     0.454167          -0.9213           0.125   \n",
       "4         0.217952     0.452916           0.9744           0.050   \n",
       "...            ...          ...              ...             ...   \n",
       "49995     0.394425     0.522897           0.9886           0.045   \n",
       "49996    -0.276190     0.642857          -0.6837           0.160   \n",
       "49997     0.056984     0.395538          -0.9734           0.181   \n",
       "49998    -0.048663     0.447034          -0.8657           0.116   \n",
       "49999     0.120000     0.637692           0.6975           0.118   \n",
       "\n",
       "       text_vader_neu  text_vader_pos  \n",
       "0               0.756           0.064  \n",
       "1               0.773           0.176  \n",
       "2               0.688           0.198  \n",
       "3               0.816           0.059  \n",
       "4               0.806           0.144  \n",
       "...               ...             ...  \n",
       "49995           0.765           0.189  \n",
       "49996           0.730           0.110  \n",
       "49997           0.704           0.115  \n",
       "49998           0.804           0.080  \n",
       "49999           0.734           0.148  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00282125, -0.48287496,  1.87121906,  0.81874365])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Regression, let's see if TextBlob and Vader are correlated\n",
    "'''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "y = training[\"text_tb_pol\"].to_numpy()\n",
    "x = training[[\"text_vader_comp\", \"text_vader_neg\", \"text_vader_pos\", \"text_vader_neu\"]].to_numpy()\n",
    "#x = training[\"text_vader_neu\"].to_numpy().reshape(-1, 1)\n",
    "reg = LinearRegression().fit(x, y)\n",
    "reg.coef_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7724906666666671, 0.772474666666667, 0.7724693333333336, 0.7724773333333335]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Begin logistic regression\n",
    "'''\n",
    "'''\n",
    "solver          penalty\n",
    "lbfgs           l2\n",
    "newton-cg       l1, l2\n",
    "sag             l2\n",
    "saga            elasticnet, l1, l2\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classes = training[\"sentiment\"].to_numpy()\n",
    "#features = training[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "'''text only'''\n",
    "features = training[[\"text_tb_pol\",  \"text_vader_pos\", \"text_vader_neg\", \"text_vader_neu\"]].to_numpy()\n",
    "\n",
    "#validate_features = testing[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "\n",
    "#for i in range(100):\n",
    "\n",
    "averages = []\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "\n",
    "#lbgfs\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "    lbgfs.fit(x_train, y_train)\n",
    "    results = lbgfs.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "''''''\n",
    "total = 0\n",
    "length = 0\n",
    "#newton-cg\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    newton_cg = LogisticRegression(penalty=\"l2\", solver=\"newton-cg\")\n",
    "    newton_cg.fit(x_train, y_train)\n",
    "    results = newton_cg.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "#sag\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    sag = LogisticRegression(penalty=\"l2\", solver=\"sag\", random_state=i)\n",
    "    sag.fit(x_train, y_train)\n",
    "    results = sag.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "#saga\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    saga = LogisticRegression(penalty=\"l2\", solver=\"saga\", random_state=i)\n",
    "    saga.fit(x_train, y_train)\n",
    "    results = saga.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "\n",
    "averages\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2895.49,  853.81],\n",
       "       [ 852.51, 2898.19]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrices = []\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "    lbgfs.fit(x_train, y_train)\n",
    "    results = lbgfs.predict(x_test)\n",
    "    actual = y_test\n",
    "    matrices.append(confusion_matrix(y_test, results))\n",
    "\n",
    "mean_matrix = np.mean(np.array(matrices), axis=0)\n",
    "mean_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=0)\n",
    "lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "lbgfs.fit(x_train, y_train)\n",
    "with open(\"IMDB_LOG.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lbgfs, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
