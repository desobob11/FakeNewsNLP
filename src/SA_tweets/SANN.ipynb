{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "\n",
    "\n",
    "training = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"sentimentdataset\")\n",
    "\n",
    "validation = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"validation\")\n",
    "testing = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"testing\")\n",
    "\n",
    "#remove nonASCIICharacters\n",
    "training[\"Text\"] = training.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "validation[\"Text\"] = validation.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "testing[\"Text\"] = testing.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(s):\n",
    "    match s:\n",
    "        case \"Positive\":\n",
    "            return 2\n",
    "        case \"Negative\":\n",
    "            return 0\n",
    "        case \"Neutral\":\n",
    "            return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[\"SimpleSent\"] = training.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)\n",
    "testing[\"SimpleSent\"] = testing.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)\n",
    "validation[\"SimpleSent\"] = validation.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDrop = [\"Timestamp\", \"User\", \"Platform\", \"Retweets\", \"Likes\", \"Country\", \"Year\", \"Month\", \"Day\", \"Hour\"]\n",
    "\n",
    "training = training.drop(toDrop, axis=1)\n",
    "testing = testing.drop(toDrop, axis=1)\n",
    "validation = validation.drop(toDrop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_words(xs):\n",
    "    empties = []\n",
    "    empty = \"\" \n",
    "    for i in xs:\n",
    "        words = re.split(r\"([A-Z])\", i)\n",
    "        words = words[1::]\n",
    "        for i in range(0, len(words) -1, 2):\n",
    "            empty += words[i] + words[i + 1]\n",
    "            empty += \" \"\n",
    "        empties.append(empty.rstrip())\n",
    "    return empties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SimpleSent</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After a series of defeats, the soccer team fac...</td>\n",
       "      <td>Disappointment</td>\n",
       "      <td>0</td>\n",
       "      <td>Disappointment and Disappointment Soccer Defeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the tennis tournament, a highly anticipated...</td>\n",
       "      <td>Frustration</td>\n",
       "      <td>0</td>\n",
       "      <td>Frustration and Frustration Tennis Setback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facing a defeat in the championship, the boxer...</td>\n",
       "      <td>Reflection</td>\n",
       "      <td>1</td>\n",
       "      <td>Reflection and Reflection Boxing Defeat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the midst of a cycling race, a tire blowout...</td>\n",
       "      <td>Obstacle</td>\n",
       "      <td>1</td>\n",
       "      <td>Obstacle and Obstacle Cycling Frustration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The gymnast's unexpected fall during a routine...</td>\n",
       "      <td>Sympathy</td>\n",
       "      <td>2</td>\n",
       "      <td>Sympathy and Sympathy Gymnastics Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Organized a community painting event, turning ...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>2</td>\n",
       "      <td>Community Art and Community Art Senior Creativity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Hosted a 'memory lane' evening with old friend...</td>\n",
       "      <td>Gratitude</td>\n",
       "      <td>2</td>\n",
       "      <td>Friendship Adventures and Friendship Adventure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Joined a seniors' astronomy club, stargazing a...</td>\n",
       "      <td>Curiosity</td>\n",
       "      <td>1</td>\n",
       "      <td>Celestial Wonders and Celestial Wonders Senior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Attended a local jazz festival, tapping toes t...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>2</td>\n",
       "      <td>Timeless Tunes and Timeless Tunes Senior Jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Started a blog sharing the wisdom gained throu...</td>\n",
       "      <td>Gratitude</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Lessons and Life Lessons Senior Blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text       Sentiment  \\\n",
       "0   After a series of defeats, the soccer team fac...  Disappointment   \n",
       "1   In the tennis tournament, a highly anticipated...     Frustration   \n",
       "2   Facing a defeat in the championship, the boxer...      Reflection   \n",
       "3   In the midst of a cycling race, a tire blowout...        Obstacle   \n",
       "4   The gymnast's unexpected fall during a routine...        Sympathy   \n",
       "..                                                ...             ...   \n",
       "86  Organized a community painting event, turning ...             Joy   \n",
       "87  Hosted a 'memory lane' evening with old friend...       Gratitude   \n",
       "88  Joined a seniors' astronomy club, stargazing a...       Curiosity   \n",
       "89  Attended a local jazz festival, tapping toes t...             Joy   \n",
       "90  Started a blog sharing the wisdom gained throu...       Gratitude   \n",
       "\n",
       "    SimpleSent                                           Hashtags  \n",
       "0            0   Disappointment and Disappointment Soccer Defeats  \n",
       "1            0         Frustration and Frustration Tennis Setback  \n",
       "2            1            Reflection and Reflection Boxing Defeat  \n",
       "3            1          Obstacle and Obstacle Cycling Frustration  \n",
       "4            2              Sympathy and Sympathy Gymnastics Fall  \n",
       "..         ...                                                ...  \n",
       "86           2  Community Art and Community Art Senior Creativity  \n",
       "87           2  Friendship Adventures and Friendship Adventure...  \n",
       "88           1  Celestial Wonders and Celestial Wonders Senior...  \n",
       "89           2      Timeless Tunes and Timeless Tunes Senior Jazz  \n",
       "90           2          Life Lessons and Life Lessons Senior Blog  \n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import *\n",
    "#process Hashtages\n",
    "training[\"proc_hash\"] = training.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "training[\"proc_hash\"] = training.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "training[\"proc_hash\"] = training.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "training[\"Hashtags\"] = training[\"proc_hash\"]\n",
    "training = training.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "testing[\"Hashtags\"] = testing[\"proc_hash\"]\n",
    "testing = testing.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "validation[\"Hashtags\"] = validation[\"proc_hash\"]\n",
    "validation = validation.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "validation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training[\"text_tb_pol\"] = training.apply(lambda x: TextBlob(x[\"Text\"]).polarity, axis=1)\n",
    "training[\"text_tb_sub\"] = training.apply(lambda x: TextBlob(x[\"Text\"]).subjectivity, axis=1)\n",
    "\n",
    "training[\"hash_tb_pol\"] = training.apply(lambda x: TextBlob(x[\"Hashtags\"]).polarity, axis=1)\n",
    "training[\"hash_tb_sub\"] = training.apply(lambda x: TextBlob(x[\"Hashtags\"]).subjectivity, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "training[\"text_vader_scores\"] = training.apply(lambda x: analyzer.polarity_scores(x[\"Text\"]), axis=1)\n",
    "training[\"text_vader_neg\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neg\"], axis=1)\n",
    "training[\"text_vader_neu\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neu\"], axis=1)\n",
    "training[\"text_vader_pos\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"pos\"], axis=1)\n",
    "training[\"text_vader_comp\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"compound\"], axis=1)\n",
    "training = training.drop([\"text_vader_scores\"], axis=1)\n",
    "\n",
    "training[\"hash_vader_scores\"] = training.apply(lambda x: analyzer.polarity_scores(x[\"Hashtags\"]), axis=1)\n",
    "training[\"hash_vader_neg\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"neg\"], axis=1)\n",
    "training[\"hash_vader_neu\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"neu\"], axis=1)\n",
    "training[\"hash_vader_pos\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"pos\"], axis=1)\n",
    "training[\"hash_vader_comp\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"compound\"], axis=1)\n",
    "training = training.drop([\"hash_vader_scores\"], axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SimpleSent</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>hash_tb_pol</th>\n",
       "      <th>hash_tb_sub</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "      <th>text_vader_comp</th>\n",
       "      <th>hash_vader_neg</th>\n",
       "      <th>hash_vader_neu</th>\n",
       "      <th>hash_vader_pos</th>\n",
       "      <th>hash_vader_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>Nature and Nature Park</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Traffic and Traffic Morning</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.4767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout!            ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>Fitness and Fitness Workout</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>Travel and Travel Adventure</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Cooking and Cooking Food</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Collaborating on a science project that receiv...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2</td>\n",
       "      <td>Science Fair Winner and Science Fair Winner Hi...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Attending a surprise birthday party organized ...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2</td>\n",
       "      <td>Surprise Celebration and Surprise Celebration ...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.9551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Successfully fundraising for a school charity ...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2</td>\n",
       "      <td>Community Giving and Community Giving High Sch...</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Participating in a multicultural festival, cel...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2</td>\n",
       "      <td>Cultural Celebration and Cultural Celebration ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.246667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Organizing a virtual talent show during challe...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>2</td>\n",
       "      <td>Virtual Entertainment and Virtual Entertainmen...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.7777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.8360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>732 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Sentiment  SimpleSent  \\\n",
       "0     Enjoying a beautiful day at the park!        ...  Positive           2   \n",
       "1     Traffic was terrible this morning.           ...  Negative           0   \n",
       "2     Just finished an amazing workout!            ...  Positive           2   \n",
       "3     Excited about the upcoming weekend getaway!  ...  Positive           2   \n",
       "4     Trying out a new recipe for dinner tonight.  ...   Neutral           1   \n",
       "..                                                 ...       ...         ...   \n",
       "727  Collaborating on a science project that receiv...     Happy           2   \n",
       "728  Attending a surprise birthday party organized ...     Happy           2   \n",
       "729  Successfully fundraising for a school charity ...     Happy           2   \n",
       "730  Participating in a multicultural festival, cel...     Happy           2   \n",
       "731  Organizing a virtual talent show during challe...     Happy           2   \n",
       "\n",
       "                                              Hashtags  text_tb_pol  \\\n",
       "0                               Nature and Nature Park     0.750000   \n",
       "1                          Traffic and Traffic Morning    -1.000000   \n",
       "2                          Fitness and Fitness Workout     0.750000   \n",
       "3                          Travel and Travel Adventure     0.468750   \n",
       "4                             Cooking and Cooking Food     0.136364   \n",
       "..                                                 ...          ...   \n",
       "727  Science Fair Winner and Science Fair Winner Hi...     0.875000   \n",
       "728  Surprise Celebration and Surprise Celebration ...     0.687500   \n",
       "729  Community Giving and Community Giving High Sch...     0.516667   \n",
       "730  Cultural Celebration and Cultural Celebration ...     1.000000   \n",
       "731  Virtual Entertainment and Virtual Entertainmen...     0.625000   \n",
       "\n",
       "     text_tb_sub  hash_tb_pol  hash_tb_sub  text_vader_neg  text_vader_neu  \\\n",
       "0       0.800000         0.00     0.000000           0.000           0.397   \n",
       "1       1.000000         0.00     0.000000           0.437           0.563   \n",
       "2       0.900000         0.00     0.000000           0.000           0.494   \n",
       "3       0.750000         0.00     0.000000           0.000           0.650   \n",
       "4       0.454545         0.00     0.000000           0.000           1.000   \n",
       "..           ...          ...          ...             ...             ...   \n",
       "727     0.900000         0.52     0.780000           0.000           0.599   \n",
       "728     0.600000         0.16     0.540000           0.000           0.327   \n",
       "729     0.383333         0.16     0.540000           0.000           0.468   \n",
       "730     1.000000         0.12     0.246667           0.000           0.479   \n",
       "731     1.000000         0.16     0.540000           0.000           0.562   \n",
       "\n",
       "     text_vader_pos  text_vader_comp  hash_vader_neg  hash_vader_neu  \\\n",
       "0             0.603           0.8221             0.0           1.000   \n",
       "1             0.000          -0.4767             0.0           1.000   \n",
       "2             0.506           0.6239             0.0           0.323   \n",
       "3             0.350           0.4003             0.0           0.566   \n",
       "4             0.000           0.0000             0.0           1.000   \n",
       "..              ...              ...             ...             ...   \n",
       "727           0.401           0.8268             0.0           0.330   \n",
       "728           0.673           0.9551             0.0           0.413   \n",
       "729           0.532           0.9098             0.0           0.556   \n",
       "730           0.521           0.8977             0.0           1.000   \n",
       "731           0.438           0.7777             0.0           0.360   \n",
       "\n",
       "     hash_vader_pos  hash_vader_comp  \n",
       "0             0.000           0.0000  \n",
       "1             0.000           0.0000  \n",
       "2             0.677           0.4939  \n",
       "3             0.434           0.3182  \n",
       "4             0.000           0.0000  \n",
       "..              ...              ...  \n",
       "727           0.670           0.9042  \n",
       "728           0.587           0.7269  \n",
       "729           0.444           0.5859  \n",
       "730           0.000           0.0000  \n",
       "731           0.640           0.8360  \n",
       "\n",
       "[732 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "20/20 - 1s - 60ms/step - accuracy: 0.6093 - loss: 1.0546\n",
      "Epoch 2/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6029 - loss: 1.0331\n",
      "Epoch 3/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6029 - loss: 1.0111\n",
      "Epoch 4/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.6029 - loss: 0.9872\n",
      "Epoch 5/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6029 - loss: 0.9622\n",
      "Epoch 6/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6029 - loss: 0.9359\n",
      "Epoch 7/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.6029 - loss: 0.9065\n",
      "Epoch 8/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6045 - loss: 0.8770\n",
      "Epoch 9/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6238 - loss: 0.8479\n",
      "Epoch 10/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6479 - loss: 0.8218\n",
      "Epoch 11/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6640 - loss: 0.7981\n",
      "Epoch 12/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.6688 - loss: 0.7785\n",
      "Epoch 13/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6768 - loss: 0.7608\n",
      "Epoch 14/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.6897 - loss: 0.7450\n",
      "Epoch 15/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7074 - loss: 0.7308\n",
      "Epoch 16/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7219 - loss: 0.7174\n",
      "Epoch 17/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7251 - loss: 0.7056\n",
      "Epoch 18/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7315 - loss: 0.6943\n",
      "Epoch 19/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7492 - loss: 0.6841\n",
      "Epoch 20/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7572 - loss: 0.6747\n",
      "Epoch 21/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7637 - loss: 0.6659\n",
      "Epoch 22/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7701 - loss: 0.6576\n",
      "Epoch 23/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7717 - loss: 0.6501\n",
      "Epoch 24/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7878 - loss: 0.6428\n",
      "Epoch 25/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.7910 - loss: 0.6360\n",
      "Epoch 26/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7974 - loss: 0.6295\n",
      "Epoch 27/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7990 - loss: 0.6235\n",
      "Epoch 28/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.7974 - loss: 0.6176\n",
      "Epoch 29/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8006 - loss: 0.6120\n",
      "Epoch 30/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8023 - loss: 0.6062\n",
      "Epoch 31/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8006 - loss: 0.6006\n",
      "Epoch 32/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8006 - loss: 0.5945\n",
      "Epoch 33/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8055 - loss: 0.5875\n",
      "Epoch 34/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8103 - loss: 0.5793\n",
      "Epoch 35/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8183 - loss: 0.5726\n",
      "Epoch 36/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8232 - loss: 0.5663\n",
      "Epoch 37/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8248 - loss: 0.5609\n",
      "Epoch 38/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8280 - loss: 0.5559\n",
      "Epoch 39/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8280 - loss: 0.5514\n",
      "Epoch 40/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8296 - loss: 0.5473\n",
      "Epoch 41/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8264 - loss: 0.5433\n",
      "Epoch 42/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8312 - loss: 0.5396\n",
      "Epoch 43/100\n",
      "20/20 - 0s - 9ms/step - accuracy: 0.8280 - loss: 0.5360\n",
      "Epoch 44/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8280 - loss: 0.5326\n",
      "Epoch 45/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8296 - loss: 0.5295\n",
      "Epoch 46/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8296 - loss: 0.5266\n",
      "Epoch 47/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8312 - loss: 0.5237\n",
      "Epoch 48/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8312 - loss: 0.5211\n",
      "Epoch 49/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8296 - loss: 0.5187\n",
      "Epoch 50/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8296 - loss: 0.5163\n",
      "Epoch 51/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8312 - loss: 0.5141\n",
      "Epoch 52/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8312 - loss: 0.5118\n",
      "Epoch 53/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.5099\n",
      "Epoch 54/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.5080\n",
      "Epoch 55/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.5062\n",
      "Epoch 56/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.5044\n",
      "Epoch 57/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8328 - loss: 0.5027\n",
      "Epoch 58/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.5011\n",
      "Epoch 59/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8328 - loss: 0.4996\n",
      "Epoch 60/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4981\n",
      "Epoch 61/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4969\n",
      "Epoch 62/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4955\n",
      "Epoch 63/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4943\n",
      "Epoch 64/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4931\n",
      "Epoch 65/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4919\n",
      "Epoch 66/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4909\n",
      "Epoch 67/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8344 - loss: 0.4899\n",
      "Epoch 68/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4891\n",
      "Epoch 69/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4883\n",
      "Epoch 70/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4871\n",
      "Epoch 71/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4863\n",
      "Epoch 72/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4855\n",
      "Epoch 73/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4847\n",
      "Epoch 74/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4840\n",
      "Epoch 75/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4834\n",
      "Epoch 76/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4829\n",
      "Epoch 77/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4830\n",
      "Epoch 78/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4820\n",
      "Epoch 79/100\n",
      "20/20 - 0s - 2ms/step - accuracy: 0.8376 - loss: 0.4811\n",
      "Epoch 80/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4811\n",
      "Epoch 81/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8376 - loss: 0.4803\n",
      "Epoch 82/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4795\n",
      "Epoch 83/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8376 - loss: 0.4789\n",
      "Epoch 84/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4786\n",
      "Epoch 85/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8376 - loss: 0.4786\n",
      "Epoch 86/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4778\n",
      "Epoch 87/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4774\n",
      "Epoch 88/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4772\n",
      "Epoch 89/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4768\n",
      "Epoch 90/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8360 - loss: 0.4766\n",
      "Epoch 91/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8376 - loss: 0.4762\n",
      "Epoch 92/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4760\n",
      "Epoch 93/100\n",
      "20/20 - 0s - 4ms/step - accuracy: 0.8376 - loss: 0.4756\n",
      "Epoch 94/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4754\n",
      "Epoch 95/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4750\n",
      "Epoch 96/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4752\n",
      "Epoch 97/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4743\n",
      "Epoch 98/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4744\n",
      "Epoch 99/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8360 - loss: 0.4742\n",
      "Epoch 100/100\n",
      "20/20 - 0s - 3ms/step - accuracy: 0.8376 - loss: 0.4747\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Begin Neural Net\n",
    "'''\n",
    "\n",
    "classes = training[\"SimpleSent\"].to_numpy()\n",
    "#features = training[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "'''text only'''\n",
    "features = training[[\"text_tb_pol\", \"text_vader_pos\", \"text_vader_neg\", \"text_vader_neu\"]].to_numpy()\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=1)\n",
    "model.fit(x_train, y_train, epochs=100, verbose=2)\n",
    "model.save(\"TWEETS_NN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 0s - 12ms/step - accuracy: 0.8376 - loss: 0.4737\n",
      "4/4 - 0s - 8ms/step - accuracy: 0.8364 - loss: 0.5361\n",
      "Train / Test Accuracy: 83.8% / 83.6%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_loss1, model_acc1 = model.evaluate(x_train,  y_train, verbose=2)\n",
    "model_loss2, model_acc2 = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(f\"Train / Test Accuracy: {model_acc1*100:.1f}% / {model_acc2*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 22, 75], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrices = []\n",
    "for i in range(100):\n",
    "  model = tf.keras.models.load_model(\"SANN.keras\")\n",
    "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "  x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "  model.fit(x_train, y_train, epochs=100)\n",
    "\n",
    "  y_pred = model.predict(x_test)\n",
    "  class_preds = np.argmax(y_pred, axis=-1)\n",
    "  matrices.append(confusion_matrix(y_test, class_preds))\n",
    "\n",
    "mean_matrix = np.mean(np.array(matrices), axis=0)\n",
    "mean_matrix\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
