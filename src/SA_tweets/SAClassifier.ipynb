{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "\n",
    "\n",
    "training = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"sentimentdataset\")\n",
    "\n",
    "validation = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"validation\")\n",
    "testing = pd.read_excel(r\"../../data/Des_SA/sentimentdataset.xlsx\", \"testing\")\n",
    "\n",
    "#remove nonASCIICharacters\n",
    "training[\"Text\"] = training.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "validation[\"Text\"] = validation.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "testing[\"Text\"] = testing.apply(lambda x: \"\".join([i for i in x[\"Text\"] if ord(i) <= 127]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_class(s):\n",
    "    match s:\n",
    "        case \"Positive\":\n",
    "            return 2\n",
    "        case \"Negative\":\n",
    "            return 1\n",
    "        case \"Neutral\":\n",
    "            return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training[\"SimpleSent\"] = training.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)\n",
    "testing[\"SimpleSent\"] = testing.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)\n",
    "validation[\"SimpleSent\"] = validation.apply(lambda x: to_class(x[\"SimpleSent\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDrop = [\"Timestamp\", \"User\", \"Platform\", \"Retweets\", \"Likes\", \"Country\", \"Year\", \"Month\", \"Day\", \"Hour\"]\n",
    "\n",
    "training = training.drop(toDrop, axis=1)\n",
    "testing = testing.drop(toDrop, axis=1)\n",
    "validation = validation.drop(toDrop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def split_words(xs):\n",
    "    empties = []\n",
    "    empty = \"\" \n",
    "    for i in xs:\n",
    "        words = re.split(r\"([A-Z])\", i)\n",
    "        words = words[1::]\n",
    "        for i in range(0, len(words) -1, 2):\n",
    "            empty += words[i] + words[i + 1]\n",
    "            empty += \" \"\n",
    "        empties.append(empty.rstrip())\n",
    "    return empties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import *\n",
    "#process Hashtages\n",
    "training[\"proc_hash\"] = training.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "training[\"proc_hash\"] = training.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "training[\"proc_hash\"] = training.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "training[\"Hashtags\"] = training[\"proc_hash\"]\n",
    "training = training.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "testing[\"proc_hash\"] = testing.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "testing[\"Hashtags\"] = testing[\"proc_hash\"]\n",
    "testing = testing.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: x[\"Hashtags\"][1::], axis=1)\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: x[\"proc_hash\"].replace(\" #\", \" and \"), axis=1)\n",
    "validation[\"proc_hash\"] = validation.apply(lambda x: \" and \".join(split_words(x[\"proc_hash\"].split(\" and \"))), axis=1)\n",
    "validation[\"Hashtags\"] = validation[\"proc_hash\"]\n",
    "validation = validation.drop(\"proc_hash\", axis=1)\n",
    "\n",
    "validation\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training[\"text_tb_pol\"] = training.apply(lambda x: TextBlob(x[\"Text\"]).polarity, axis=1)\n",
    "training[\"text_tb_sub\"] = training.apply(lambda x: TextBlob(x[\"Text\"]).subjectivity, axis=1)\n",
    "\n",
    "training[\"hash_tb_pol\"] = training.apply(lambda x: TextBlob(x[\"Hashtags\"]).polarity, axis=1)\n",
    "training[\"hash_tb_sub\"] = training.apply(lambda x: TextBlob(x[\"Hashtags\"]).subjectivity, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "training[\"text_vader_scores\"] = training.apply(lambda x: analyzer.polarity_scores(x[\"Text\"]), axis=1)\n",
    "training[\"text_vader_neg\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neg\"], axis=1)\n",
    "training[\"text_vader_neu\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"neu\"], axis=1)\n",
    "training[\"text_vader_pos\"] = training.apply(lambda x: x[\"text_vader_scores\"][\"pos\"], axis=1)\n",
    "training = training.drop([\"text_vader_scores\"], axis=1)\n",
    "\n",
    "training[\"hash_vader_scores\"] = training.apply(lambda x: analyzer.polarity_scores(x[\"Hashtags\"]), axis=1)\n",
    "training[\"hash_vader_neg\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"neg\"], axis=1)\n",
    "training[\"hash_vader_neu\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"neu\"], axis=1)\n",
    "training[\"hash_vader_pos\"] = training.apply(lambda x: x[\"hash_vader_scores\"][\"pos\"], axis=1)\n",
    "training = training.drop([\"hash_vader_scores\"], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Begin logistic regression\n",
    "'''\n",
    "'''\n",
    "solver          penalty\n",
    "lbfgs           l2\n",
    "newton-cg       l1, l2\n",
    "sag             l2\n",
    "saga            elasticnet, l1, l2\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "classes = training[\"SimpleSent\"].to_numpy()\n",
    "#features = training[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "'''text only'''\n",
    "features = training[[\"text_tb_pol\", \"text_vader_pos\", \"text_vader_neg\", \"text_vader_neu\"]].to_numpy()\n",
    "\n",
    "#validate_features = testing[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "\n",
    "#for i in range(100):\n",
    "\n",
    "averages = []\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "\n",
    "#lbgfs\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "    lbgfs.fit(x_train, y_train)\n",
    "    results = lbgfs.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "''''''\n",
    "total = 0\n",
    "length = 0\n",
    "#newton-cg\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    newton_cg = LogisticRegression(penalty=\"l2\", solver=\"newton-cg\")\n",
    "    newton_cg.fit(x_train, y_train)\n",
    "    results = newton_cg.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "#sag\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    sag = LogisticRegression(penalty=\"l2\", solver=\"sag\", random_state=i)\n",
    "    sag.fit(x_train, y_train)\n",
    "    results = sag.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "total = 0\n",
    "length = 0\n",
    "#saga\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    saga = LogisticRegression(penalty=\"l2\", solver=\"saga\", random_state=i)\n",
    "    saga.fit(x_train, y_train)\n",
    "    results = saga.predict(x_test)\n",
    "    actual = y_test\n",
    "    total += (len([i for i in zip(results, actual) if i[0] == i[1]]) / len(actual))\n",
    "    length += 1\n",
    "averages.append(total / length)\n",
    "\n",
    "\n",
    "averages\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrices = []\n",
    "for i in range(100):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=i)\n",
    "    lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "    lbgfs.fit(x_train, y_train)\n",
    "    results = lbgfs.predict(x_test)\n",
    "    actual = y_test\n",
    "    matrices.append(confusion_matrix(y_test, results))\n",
    "\n",
    "mean_matrix = np.mean(np.array(matrices), axis=0)\n",
    "mean_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=0)\n",
    "lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "lbgfs.fit(x_train, y_train)\n",
    "with open(\"TWEETS_LOG.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lbgfs, file)\n",
    "#results = lbgfs.predict(x_test)\n",
    "#actual = y_test\n",
    "#matrices.append(confusion_matrix(y_test, results))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
