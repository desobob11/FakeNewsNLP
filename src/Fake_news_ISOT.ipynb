{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    ISOT\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/ISOT_PROCESSED.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy, textblob and vader: 71.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3510, 3221], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Scale embeddings\n",
    "\n",
    "\n",
    "#features = training[[\"text_tb_pol\", \"text_tb_sub\", \"hash_tb_pol\", \"hash_tb_sub\", \"text_vader_neg\", \"text_vader_neu\", \"text_vader_pos\", \"hash_vader_neg\", \"hash_vader_neu\", \"hash_vader_pos\"]].to_numpy()\n",
    "\n",
    "'''text only'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"].to_numpy()\n",
    "#features = filtered[[\"title_vader_class\", \"text_vader_class\", \"text_tb_pol_class\", \"text_tb_sub_class\", \"title_tb_pol_class\", \"title_tb_sub_class\"]].dropna()\n",
    "\n",
    "'''\n",
    "  Tweet classifier\n",
    "[\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", title_log_tweets\"]\n",
    "'''\n",
    "\n",
    "tweet_features = [\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", \"title_log_tweets\", \"text_tb_sub_class\", \"title_tb_sub_class\"]\n",
    "imdb_features = [\"text_NN_imdb\", \"title_NN_imdb\", \"text_log_imdb\", \"title_log_imdb\"]\n",
    "\n",
    "tweet_and_imdb = [i for i in tweet_features]\n",
    "tweet_and_imdb.extend(imdb_features)\n",
    "\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_comp\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]].to_numpy()\n",
    "\n",
    "\n",
    "#for i in range(100):\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=42)\n",
    "#x_train\n",
    "\n",
    "ensemble = LogisticRegression()\n",
    "ensemble.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate predictions\n",
    "y_pred = ensemble.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Ensemble accuracy, textblob and vader: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "uniques, counts = np.unique(y_test, return_counts=True)\n",
    "counts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desmo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1192/1192 - 2s - 2ms/step - accuracy: 0.6475 - loss: 0.6235\n",
      "Epoch 2/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7199 - loss: 0.5606\n",
      "Epoch 3/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7340 - loss: 0.5410\n",
      "Epoch 4/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7437 - loss: 0.5273\n",
      "Epoch 5/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7500 - loss: 0.5156\n",
      "Epoch 6/10\n",
      "1192/1192 - 1s - 962us/step - accuracy: 0.7548 - loss: 0.5064\n",
      "Epoch 7/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7597 - loss: 0.4993\n",
      "Epoch 8/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7642 - loss: 0.4935\n",
      "Epoch 9/10\n",
      "1192/1192 - 3s - 2ms/step - accuracy: 0.7669 - loss: 0.4897\n",
      "Epoch 10/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7684 - loss: 0.4859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15aba655f10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(12, 1)),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "'''text only'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"].to_numpy()\n",
    "#features = filtered[[\"title_vader_class\", \"text_vader_class\", \"text_tb_pol_class\", \"text_tb_sub_class\", \"title_tb_pol_class\", \"title_tb_sub_class\"]].to_numpy()\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_comp\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]].to_numpy()\n",
    "\n",
    "'''\n",
    "  Tweet classifier\n",
    "[\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", title_log_tweets\"]\n",
    "'''\n",
    "\n",
    "tweet_features = [\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", \"title_log_tweets\"]\n",
    "#imdb_features = [\"text_NN_imdb\", \"title_NN_imdb\", \"text_log_imdb\", \"title_log_imdb\"]\n",
    "\n",
    "tweet_and_imdb = [i for i in tweet_features]\n",
    "tweet_and_imdb.extend(imdb_features)\n",
    "\n",
    "#features = filtered[tweet_and_imdb].to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, classes, test_size=0.15, random_state=42)\n",
    "model.fit(x_train, y_train, epochs=10, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
