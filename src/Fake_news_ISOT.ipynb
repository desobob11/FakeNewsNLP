{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    ISOT\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/ISOT_PROCESSED.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Define filtered dataset, classes, and features\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"].to_numpy()\n",
    "\n",
    "#just tweet sentiment classifier\n",
    "tweet_features = filtered[[\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", \"title_log_tweets\", \"text_tb_sub_class\", \"title_tb_sub_class\"]].to_numpy()\n",
    "\n",
    "#just imbd sentiment classifier\n",
    "imdb_features = filtered[[\"text_NN_imdb\", \"title_NN_imdb\", \"text_log_imdb\", \"title_log_imdb\"]].to_numpy()\n",
    "\n",
    "# both sentiment classifiers\n",
    "tweet_and_imdb = filtered[[\"text_NN_tweets\", \"title_NN_tweets\", \"text_log_tweets\", \"title_log_tweets\", \"text_tb_sub_class\", \"title_tb_sub_class\",\n",
    "                           \"text_NN_imdb\", \"title_NN_imdb\", \"text_log_imdb\", \"title_log_imdb\"]].to_numpy()\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "raw_features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_comp\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]].to_numpy()\n",
    "\n",
    "# dataframe to store accuracies for NN and log regression\n",
    "accuracy_df = pd.DataFrame(columns=[\"tweet_classifier\",\n",
    "               \"imdb_classifier\",\n",
    "               \"combined_classifier\",\n",
    "               \"raw_sentiments\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desmo\\AppData\\Local\\Temp\\ipykernel_6564\\3418070271.py:76: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = book\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_classifier</th>\n",
       "      <th>imdb_classifier</th>\n",
       "      <th>combined_classifier</th>\n",
       "      <th>raw_sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log Regression</th>\n",
       "      <td>0.640172</td>\n",
       "      <td>0.525776</td>\n",
       "      <td>0.640024</td>\n",
       "      <td>0.709404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_classifier  imdb_classifier  combined_classifier  \\\n",
       "Log Regression          0.640172         0.525776             0.640024   \n",
       "\n",
       "                raw_sentiments  \n",
       "Log Regression        0.709404  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "  Logistic Regression outputs\n",
    "'''\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "logOutput = {}\n",
    "logMatrices = {\"tweet_classifier\" : [],\n",
    "               \"imdb_classifier\" : [],\n",
    "               \"combined_classifier\": [],\n",
    "               \"raw_sentiments\" : []}\n",
    "\n",
    "# sums\n",
    "tweet_scores = 0\n",
    "imdb_scores = 0\n",
    "tweet_imdb_scores = 0\n",
    "raw_scores = 0\n",
    "\n",
    "# log regression model, LBFGS with L2 penalty\n",
    "lbgfs = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\")\n",
    "\n",
    "# run 100 iterations\n",
    "for i in range(1):\n",
    "  print(f\"Iteration {i}\")\n",
    "  #tweet_accuracy\n",
    "  x_train, x_test, y_train, y_test = train_test_split(tweet_features, classes, test_size=0.15, random_state=i)\n",
    "  lbgfs.fit(x_train, y_train)\n",
    "  y_pred = lbgfs.predict(x_test)\n",
    "  tweet_scores += accuracy_score(y_test, y_pred)\n",
    "  logMatrices[\"tweet_classifier\"].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(imdb_features, classes, test_size=0.15, random_state=i)\n",
    "  lbgfs.fit(x_train, y_train)\n",
    "  y_pred = lbgfs.predict(x_test)\n",
    "  imdb_scores += accuracy_score(y_test, y_pred)\n",
    "  logMatrices[\"imdb_classifier\"].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(tweet_and_imdb, classes, test_size=0.15, random_state=i)\n",
    "  lbgfs.fit(x_train, y_train)\n",
    "  y_pred = lbgfs.predict(x_test)\n",
    "  tweet_imdb_scores += accuracy_score(y_test, y_pred)\n",
    "  logMatrices[\"combined_classifier\"].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "  x_train, x_test, y_train, y_test = train_test_split(raw_features, classes, test_size=0.15, random_state=i)\n",
    "  lbgfs.fit(x_train, y_train)\n",
    "  y_pred = lbgfs.predict(x_test)\n",
    "  raw_scores += accuracy_score(y_test, lbgfs.predict(x_test))\n",
    "  logMatrices[\"raw_sentiments\"].append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "logOutput[\"tweet_classifier\"] = tweet_scores / 1\n",
    "logOutput[\"imdb_classifier\"] = imdb_scores / 1\n",
    "logOutput[\"combined_classifier\"] = tweet_imdb_scores / 1\n",
    "logOutput[\"raw_sentiments\"] = raw_scores / 1\n",
    "\n",
    "logMatrices[\"tweet_classifier\"] = np.mean(np.array(logMatrices[\"tweet_classifier\"]), axis=0)\n",
    "logMatrices[\"imdb_classifier\"] = np.mean(np.array(logMatrices[\"imdb_classifier\"]), axis=0)\n",
    "logMatrices[\"combined_classifier\"] = np.mean(np.array(logMatrices[\"combined_classifier\"]), axis=0)\n",
    "logMatrices[\"raw_sentiments\"] = np.mean(np.array(logMatrices[\"raw_sentiments\"]), axis=0)\n",
    "\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=r\"../data/Des_fake_news/ISOT_RESULTS.xlsx\")\n",
    "\n",
    "# write confusion matrices and save\n",
    "book = load_workbook(r\"../data/Des_fake_news/ISOT_RESULTS.xlsx\")\n",
    "writer = pd.ExcelWriter(r\"../data/Des_fake_news/ISOT_RESULTS.xlsx\", engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "for i in logMatrices.keys():\n",
    "  pd.DataFrame(logMatrices[i]).to_excel(writer, sheet_name=f\"matrix_log_{i}\")\n",
    "\n",
    "book.save(filename=r\"../data/Des_fake_news/ISOT_RESULTS.xlsx\")\n",
    "\n",
    "accuracy_df.loc[\"Log Regression\"] = logOutput\n",
    "accuracy_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\desmo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1192/1192 - 2s - 2ms/step - accuracy: 0.6475 - loss: 0.6235\n",
      "Epoch 2/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7199 - loss: 0.5606\n",
      "Epoch 3/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7340 - loss: 0.5410\n",
      "Epoch 4/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7437 - loss: 0.5273\n",
      "Epoch 5/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7500 - loss: 0.5156\n",
      "Epoch 6/10\n",
      "1192/1192 - 1s - 962us/step - accuracy: 0.7548 - loss: 0.5064\n",
      "Epoch 7/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7597 - loss: 0.4993\n",
      "Epoch 8/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7642 - loss: 0.4935\n",
      "Epoch 9/10\n",
      "1192/1192 - 3s - 2ms/step - accuracy: 0.7669 - loss: 0.4897\n",
      "Epoch 10/10\n",
      "1192/1192 - 1s - 1ms/step - accuracy: 0.7684 - loss: 0.4859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15aba655f10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "nnOutputs = {}\n",
    "nnMatrices = {\"tweet_classifier\" : [],\n",
    "               \"imdb_classifier\" : [],\n",
    "               \"combined_classifier\": [],\n",
    "               \"raw_sentiments\" : []}\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(len(tweet_features), 1)),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(tweet_features, classes, test_size=0.15, random_state=42)\n",
    "model.fit(x_train, y_train, epochs=10, verbose=2)\n",
    "nnOutputs[\"tweet_classifier\"] = model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
