{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    WELFAKE\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/ISOT_PROCESSED.csv\")\n",
    "data[\"flag\"] = data[\"label\"]\n",
    "data = data.sample(20000)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Add tf-idf vectorizer\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_tf_idf_vector(corpus: pd.Series) -> tuple[pd.DataFrame, list[str], TfidfVectorizer]:\n",
    "    #temp = pd.concat((x, corpus), axis=1).reset_index()\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stop_words, max_features=500, ngram_range=(1,3))\n",
    "    tf_idf_features = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "    names = vectorizer.get_feature_names_out()\n",
    "    headers = [f\"__word{i}\" for i in range(len(names))]\n",
    "    feature_frame = pd.DataFrame(tf_idf_features, columns=headers).reset_index(drop=True)\n",
    "    return (feature_frame.reset_index(drop=True), names, vectorizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "'''\n",
    "    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"]\n",
    "\n",
    "filtered[\"corpus\"] = filtered.apply(lambda x: \" \".join([x[\"title\"], x[\"text\"]]), axis=1)\n",
    "\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]]\n",
    "\n",
    "\n",
    "\n",
    "EXCEL_FILE = r\"../data/Des_fake_news/Sentiment_Analysis_Results/ISOT_RESULTS.xlsx\"\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    POLARITY + TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "comb_output = {\"train\" : None, \"test\" : None}\n",
    "comb_matrices = []\n",
    "\n",
    "\n",
    "comb_fpr = []\n",
    "comb_tpr = []\n",
    "comb_thresh = []\n",
    "\n",
    "comb_auc = 0\n",
    "\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    tf_idf_training, names, vectorizer = get_tf_idf_vector(filtered[\"corpus\"].iloc[train_index])\n",
    "    x_train = pd.concat((x.iloc[train_index].reset_index(drop=True), tf_idf_training), axis=1)\n",
    "    \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = pd.DataFrame(vectorizer.transform(filtered[\"corpus\"].iloc[test_index]).toarray(), columns=[f\"__word{i}\" for i in range(len(names))])\n",
    "    x_test = pd.concat((x.iloc[test_index].reset_index(drop=True), x_test), axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    comb_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    comb_ensemble.fit(x_train, y_train)\n",
    "    y_pred = comb_ensemble.predict(x_test)\n",
    "\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    comb_fpr.append(fpr)\n",
    "    comb_tpr.append(tpr)\n",
    "    comb_thresh.append(thresh)\n",
    "    comb_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    comb_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = comb_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "comb_output[\"test\"] = [(test_total / run_count)]\n",
    "comb_output[\"train\"] = [(train_total / run_count)]\n",
    "comb_output = pd.DataFrame(comb_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "comb_matrices = np.mean(np.array(comb_matrices), axis=0)\n",
    "print(comb_matrices)\n",
    "\n",
    "\n",
    "comb_fpr = np.mean(np.array(comb_fpr), axis=0)\n",
    "comb_tpr = np.mean(np.array(comb_tpr), axis=0)\n",
    "comb_thresh = np.mean(np.array(comb_thresh), axis=0)\n",
    "\n",
    "comb_auc = comb_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    POLARITY\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "pol_output = {\"train\" : None, \"test\" : None}\n",
    "pol_matrices = []\n",
    "\n",
    "\n",
    "pol_fpr = []\n",
    "pol_tpr = []\n",
    "pol_thresh = []\n",
    "\n",
    "pol_auc = 0\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = x.iloc[train_index]\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = x.iloc[test_index]\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    pol_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    pol_ensemble.fit(x_train, y_train)\n",
    "    y_pred = pol_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    pol_fpr.append(fpr)\n",
    "    pol_tpr.append(tpr)\n",
    "    pol_thresh.append(thresh)\n",
    "    pol_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    pol_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = pol_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "pol_output[\"test\"] = [(test_total / run_count)]\n",
    "pol_output[\"train\"] = [(train_total / run_count)]\n",
    "pol_output = pd.DataFrame(pol_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "pol_matrices = np.mean(np.array(pol_matrices), axis=0)\n",
    "print(pol_matrices)\n",
    "\n",
    "pol_fpr = np.mean(np.array(pol_fpr), axis=0)\n",
    "pol_tpr = np.mean(np.array(pol_tpr), axis=0)\n",
    "pol_thresh = np.mean(np.array(pol_thresh), axis=0)\n",
    "\n",
    "pol_auc = pol_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pol_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "tf_output = {\"train\" : None, \"test\" : None}\n",
    "tf_matrices = []\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "tf_fpr = []\n",
    "tf_tpr = []\n",
    "tf_thresh = []\n",
    "\n",
    "tf_auc = 0\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    tf_idf_training, names, vectorizer = get_tf_idf_vector(filtered[\"corpus\"].iloc[train_index])\n",
    "    x_train = pd.concat((x.iloc[train_index].reset_index(drop=True), tf_idf_training), axis=1).drop(features, axis=1)\n",
    "    \n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = pd.DataFrame(vectorizer.transform(filtered[\"corpus\"].iloc[test_index]).toarray(), columns=[f\"__word{i}\" for i in range(len(names))])\n",
    "    x_test = pd.concat((x.iloc[test_index].reset_index(drop=True), x_test), axis=1).drop(features, axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    tf_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    tf_ensemble.fit(x_train, y_train)\n",
    "    y_pred = tf_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    tf_fpr.append(fpr)\n",
    "    tf_tpr.append(tpr)\n",
    "    tf_thresh.append(thresh)\n",
    "    tf_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    tf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = tf_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "tf_output[\"test\"] = [(test_total / run_count)]\n",
    "tf_output[\"train\"] = [(train_total / run_count)]\n",
    "tf_output = pd.DataFrame(tf_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "tf_matrices = np.mean(np.array(tf_matrices), axis=0)\n",
    "print(tf_matrices)\n",
    "\n",
    "tf_fpr = np.mean(np.array(tf_fpr), axis=0)\n",
    "tf_tpr = np.mean(np.array(tf_tpr), axis=0)\n",
    "tf_thresh = np.mean(np.array(tf_thresh), axis=0)\n",
    "\n",
    "tf_auc = tf_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    combine accuracies into one table\n",
    "'''\n",
    "\n",
    "final_results = pd.concat((pol_output, tf_output, comb_output), axis=0)\n",
    "final_results.index = [\"Polarity\", \"Tf-Idf\", \"Polarity + Tf-Idf\"]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finally, save accuracy metrics to the spreadsheet\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "final_results.to_excel(writer, sheet_name=f\"accuracies\")\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(pol_fpr, pol_tpr,\n",
    " lw=lw, label='Polarity: (%0.2f)' % pol_auc)\n",
    "plt.plot(tf_fpr, tf_tpr,\n",
    " lw=lw, label='Tf-Idf: (%0.2f)' % tf_auc)\n",
    "plt.plot(comb_fpr, comb_tpr,\n",
    " lw=lw, label='Polarity + Tf-Idf: (%0.2f)' % comb_auc)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# save figure as PNG\n",
    "png = io.BytesIO()\n",
    "plt.savefig(png, format=\"png\")\n",
    "\n",
    "\n",
    "# write PNG to excel file\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "ws = book.active\n",
    "\n",
    "img = openpyxl.drawing.image.Image(png)\n",
    "img.anchor = \"A1\"\n",
    "ws.add_image(img)\n",
    "book.save(filename=EXCEL_FILE)\n",
    "plt.close()\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
