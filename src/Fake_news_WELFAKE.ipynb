{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>title_tb_pol</th>\n",
       "      <th>title_tb_sub</th>\n",
       "      <th>title_vader_comp</th>\n",
       "      <th>title_vader_neg</th>\n",
       "      <th>title_vader_neu</th>\n",
       "      <th>title_vader_pos</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>30617</td>\n",
       "      <td>30617</td>\n",
       "      <td>Ex New York Officer Gets  Years of Probation i...</td>\n",
       "      <td>Former Officer Peter Liang will not serve any ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.412762</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>34112</td>\n",
       "      <td>34112</td>\n",
       "      <td>MarkLevin is Freaking Awesome  Obama negotiate...</td>\n",
       "      <td>Let s get real with some awesome truth from Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>41186</td>\n",
       "      <td>41186</td>\n",
       "      <td>South Korean President Moon to visit China Dec...</td>\n",
       "      <td>BEIJING  Reuters    South Korean President Moo...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.058333</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>63751</td>\n",
       "      <td>63751</td>\n",
       "      <td>Is Westworld HBOs Next Big Hit    The New York...</td>\n",
       "      <td>On the morning they finished shooting the pilo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166959</td>\n",
       "      <td>0.466318</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.184848</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>27516</td>\n",
       "      <td>27516</td>\n",
       "      <td>TRUMP ADVISOR Has Warning For Syria That Has S...</td>\n",
       "      <td>Deputy Assistant to the President Sebastian Go...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.048214</td>\n",
       "      <td>0.310714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>25089</td>\n",
       "      <td>25089</td>\n",
       "      <td>Donald Trump Sends Executive Order Lawsuit to ...</td>\n",
       "      <td>The Department of Justice is formally objectin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084398</td>\n",
       "      <td>0.481746</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>12343</td>\n",
       "      <td>12343</td>\n",
       "      <td>WATCH  General BOMBARDS Trump For The Most An...</td>\n",
       "      <td>As you may already know  Trump recently shocke...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059167</td>\n",
       "      <td>0.491333</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.3804</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.097</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>13639</td>\n",
       "      <td>13639</td>\n",
       "      <td>Putin and Macron discuss North Korea s missile...</td>\n",
       "      <td>MOSCOW  Reuters    Russian President Vladimir ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>63136</td>\n",
       "      <td>63136</td>\n",
       "      <td>Comment on Hillary Clinton is an alcoholic by ...</td>\n",
       "      <td>The American Medical Association defines an al...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.013639</td>\n",
       "      <td>0.422944</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>14282</td>\n",
       "      <td>14282</td>\n",
       "      <td>Battle for the Ages</td>\n",
       "      <td>Here s something interesting from The Unz Revi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084973</td>\n",
       "      <td>0.461515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "3190         30617       30617   \n",
       "1872         34112       34112   \n",
       "3931         41186       41186   \n",
       "2378         63751       63751   \n",
       "2113         27516       27516   \n",
       "...            ...         ...   \n",
       "3749         25089       25089   \n",
       "4751         12343       12343   \n",
       "3877         13639       13639   \n",
       "1000         63136       63136   \n",
       "2687         14282       14282   \n",
       "\n",
       "                                                  title  \\\n",
       "3190  Ex New York Officer Gets  Years of Probation i...   \n",
       "1872  MarkLevin is Freaking Awesome  Obama negotiate...   \n",
       "3931  South Korean President Moon to visit China Dec...   \n",
       "2378  Is Westworld HBOs Next Big Hit    The New York...   \n",
       "2113  TRUMP ADVISOR Has Warning For Syria That Has S...   \n",
       "...                                                 ...   \n",
       "3749  Donald Trump Sends Executive Order Lawsuit to ...   \n",
       "4751   WATCH  General BOMBARDS Trump For The Most An...   \n",
       "3877  Putin and Macron discuss North Korea s missile...   \n",
       "1000  Comment on Hillary Clinton is an alcoholic by ...   \n",
       "2687                                Battle for the Ages   \n",
       "\n",
       "                                                   text  label  text_tb_pol  \\\n",
       "3190  Former Officer Peter Liang will not serve any ...      0     0.012942   \n",
       "1872  Let s get real with some awesome truth from Ma...      1     0.450000   \n",
       "3931  BEIJING  Reuters    South Korean President Moo...      0    -0.058333   \n",
       "2378  On the morning they finished shooting the pilo...      0     0.166959   \n",
       "2113  Deputy Assistant to the President Sebastian Go...      1    -0.048214   \n",
       "...                                                 ...    ...          ...   \n",
       "3749  The Department of Justice is formally objectin...      0     0.084398   \n",
       "4751  As you may already know  Trump recently shocke...      1     0.059167   \n",
       "3877  MOSCOW  Reuters    Russian President Vladimir ...      0     0.150000   \n",
       "1000  The American Medical Association defines an al...      1    -0.013639   \n",
       "2687  Here s something interesting from The Unz Revi...      1     0.084973   \n",
       "\n",
       "      text_tb_sub  title_tb_pol  title_tb_sub  title_vader_comp  \\\n",
       "3190     0.412762      0.136364      0.454545           -0.5423   \n",
       "1872     0.433333      0.525000      0.750000           -0.3400   \n",
       "3931     0.341667      0.000000      0.000000            0.0000   \n",
       "2378     0.466318      0.045455      0.184848            0.0000   \n",
       "2113     0.310714      0.000000      0.000000            0.1027   \n",
       "...           ...           ...           ...               ...   \n",
       "3749     0.481746      0.250000      0.500000           -0.2263   \n",
       "4751     0.491333      0.183333      0.333333           -0.3804   \n",
       "3877     0.325000      0.000000      0.000000            0.0000   \n",
       "1000     0.422944     -0.250000      0.500000            0.0000   \n",
       "2687     0.461515      0.000000      0.000000           -0.3818   \n",
       "\n",
       "      title_vader_neg  title_vader_neu  title_vader_pos  text_vader_neg  \\\n",
       "3190            0.189            0.811            0.000           0.153   \n",
       "1872            0.275            0.551            0.174           0.092   \n",
       "3931            0.000            1.000            0.000           0.094   \n",
       "2378            0.000            1.000            0.000           0.057   \n",
       "2113            0.169            0.634            0.197           0.170   \n",
       "...               ...              ...              ...             ...   \n",
       "3749            0.174            0.826            0.000           0.105   \n",
       "4751            0.147            0.853            0.000           0.101   \n",
       "3877            0.000            1.000            0.000           0.092   \n",
       "1000            0.000            1.000            0.000           0.133   \n",
       "2687            0.464            0.536            0.000           0.100   \n",
       "\n",
       "      text_vader_neu  text_vader_pos  flag  \n",
       "3190           0.723           0.124     0  \n",
       "1872           0.723           0.185     1  \n",
       "3931           0.886           0.020     0  \n",
       "2378           0.816           0.127     0  \n",
       "2113           0.761           0.069     1  \n",
       "...              ...             ...   ...  \n",
       "3749           0.810           0.085     0  \n",
       "4751           0.802           0.097     1  \n",
       "3877           0.849           0.059     0  \n",
       "1000           0.790           0.076     1  \n",
       "2687           0.817           0.083     1  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    WELFAKE\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/WELFAKE_PROCESSED.csv\")\n",
    "data[\"flag\"] = data[\"label\"]\n",
    "data = data.sample(100)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Add tf-idf vectorizer\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "def tf_idf_vectorize(df: pd.DataFrame, corpus: pd.Series, vocabulary: list[str]) -> tuple[list[str], pd.DataFrame]:\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stop_words, max_features=500, ngram_range=(1,3), vocabulary=vocabulary)\n",
    "    features = vectorizer.fit_transform(corpus).toarray()\n",
    "    names = vectorizer.get_feature_names_out()\n",
    "    headers = [f\"__word{i}\" for i in range(len(names))]\n",
    "    feature_frame = pd.DataFrame(features, columns=headers)\n",
    "    #final = pd.concat([df, feature_frame], axis=1)\n",
    "    return (names, feature_frame)\n",
    "\n",
    "\n",
    "def get_full_vocabulary(corpus: pd.Series) -> list[str]:\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stopwords.words(\"english\"), max_features=500, ngram_range=(1,3))\n",
    "    vectorizer.fit_transform(corpus).toarray()\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "def add_tf_idf_vector(x: pd.DataFrame, partial_corpus: pd.Series, full_corpus: pd.Series) -> pd.DataFrame:\n",
    "    temp = pd.concat((x, partial_corpus), axis=1).reset_index()\n",
    "    # first, we need a vocabulary from the entire dataset\n",
    "    vocabulary = get_full_vocabulary(full_corpus)\n",
    "\n",
    "    tf_idf_vector = tf_idf_vectorize(temp, temp[partial_corpus.name], vocabulary=vocabulary)[1].reset_index()\n",
    "    temp = temp.reset_index()\n",
    "    temp = pd.concat((temp, tf_idf_vector), axis=1).drop([partial_corpus.name, \"index\"], axis=1)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "'''\n",
    "    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"]\n",
    "\n",
    "filtered[\"corpus\"] = filtered.apply(lambda x: \" \".join([x[\"title\"], x[\"text\"]]), axis=1)\n",
    "\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]]\n",
    "\n",
    "# dataframe to store accuracies for NN and log regression\n",
    "#accuracy_df = pd.DataFrame(columns=[\"polarity\",\n",
    "#               \"tfidf\",\n",
    "#               \"combined\"])\n",
    "\n",
    "\n",
    "EXCEL_FILE = r\"../data/Des_fake_news/Sentiment_Analysis_Results/WELFAKE_RESULTS.xlsx\"\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "'''\n",
    "    Get ROC plot ready\n",
    "'''\n",
    "plt.figure()\n",
    "lw = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (1, 3) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 67\u001b[0m\n\u001b[0;32m     65\u001b[0m comb_tpr\u001b[38;5;241m.\u001b[39mappend(tpr)\n\u001b[0;32m     66\u001b[0m comb_thresh\u001b[38;5;241m.\u001b[39mappend(thresh)\n\u001b[1;32m---> 67\u001b[0m comb_auc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomb_fpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomb_tpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m comb_matrices\u001b[38;5;241m.\u001b[39mappend(confusion_matrix(y_test, y_pred))\n\u001b[0;32m     70\u001b[0m test_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\desmo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\desmo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:91\u001b[0m, in \u001b[0;36mauc\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute Area Under the Curve (AUC) using the trapezoidal rule.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mThis is a general function, given points on a curve.  For computing the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mnp.float64(0.75)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m check_consistent_length(x, y)\n\u001b[1;32m---> 91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn_or_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\desmo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1395\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1396\u001b[0m             (\n\u001b[0;32m   1397\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA column-vector y was passed when a 1d array was\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1402\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1403\u001b[0m         )\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _asarray_with_order(xp\u001b[38;5;241m.\u001b[39mreshape(y, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m-> 1406\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my should be a 1d array, got an array of shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(shape)\n\u001b[0;32m   1408\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1, 3) instead."
     ]
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY + TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "comb_output = {\"train\" : None, \"test\" : None}\n",
    "comb_matrices = []\n",
    "\n",
    "\n",
    "comb_fpr = []\n",
    "comb_tpr = []\n",
    "comb_thresh = []\n",
    "\n",
    "comb_auc = 0\n",
    "\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"])\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    comb_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    comb_ensemble.fit(x_train, y_train)\n",
    "    y_pred = comb_ensemble.predict(x_test)\n",
    "\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    comb_fpr.append(fpr)\n",
    "    comb_tpr.append(tpr)\n",
    "    comb_thresh.append(thresh)\n",
    "    comb_auc += metrics.auc(fpr, fpr)\n",
    "\n",
    "    comb_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = comb_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "comb_output[\"test\"] = [(test_total / run_count)]\n",
    "comb_output[\"train\"] = [(train_total / run_count)]\n",
    "comb_output = pd.DataFrame(comb_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "comb_matrices = np.mean(np.array(comb_matrices), axis=0)\n",
    "print(comb_matrices)\n",
    "\n",
    "\n",
    "comb_fpr = np.mean(np.array(comb_fpr), axis=0)\n",
    "comb_tpr = np.mean(np.array(comb_tpr), axis=0)\n",
    "comb_thresh = np.mean(np.array(comb_thresh), axis=0)\n",
    "\n",
    "comb_auc = comb_auc / float(run_count)\n",
    "\n",
    "\n",
    "plt.plot(comb_fpr, comb_tpr,\n",
    " lw=lw, label='Polarity + Tf-Idf  (%0.2f)' % comb_auc)\n",
    "\n",
    "# write confusion matrix and save\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "\n",
    "pd.DataFrame(comb_matrices).to_excel(writer, sheet_name=f\"combined_matrix\")\n",
    "\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    POLARITY\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "pol_output = {\"train\" : None, \"test\" : None}\n",
    "pol_matrices = []\n",
    "\n",
    "\n",
    "pol_fpr = []\n",
    "pol_tpr = []\n",
    "pol_thresh = []\n",
    "\n",
    "pol_auc = 0\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "  \n",
    "    x_train = x.iloc[train_index]\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    x_test = x.iloc[test_index]\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    pol_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    pol_ensemble.fit(x_train, y_train)\n",
    "    y_pred = pol_ensemble.predict(x_test)\n",
    "\n",
    "    pol_fpr.append(fpr)\n",
    "    pol_tpr.append(tpr)\n",
    "    pol_thresh.append(thresh)\n",
    "    pol_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    pol_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = pol_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "pol_output[\"test\"] = [(test_total / run_count)]\n",
    "pol_output[\"train\"] = [(train_total / run_count)]\n",
    "pol_output = pd.DataFrame(pol_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "pol_matrices = np.mean(np.array(pol_matrices), axis=0)\n",
    "print(pol_matrices)\n",
    "\n",
    "pol_fpr = np.mean(np.array(pol_fpr), axis=0)\n",
    "pol_tpr = np.mean(np.array(pol_tpr), axis=0)\n",
    "pol_thresh = np.mean(np.array(pol_thresh), axis=0)\n",
    "\n",
    "pol_auc = pol_auc / float(run_count)\n",
    "\n",
    "\n",
    "plt.plot(pol_fpr, pol_tpr,\n",
    " lw=lw, label='Polarity  (%0.2f)' % pol_auc)\n",
    "\n",
    "# write confusion matrix and save\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "riter = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "\n",
    "pd.DataFrame(pol_matrices).to_excel(writer, sheet_name=f\"polarity_matrix\")\n",
    "\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n",
    "\n",
    "pol_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "tf_output = {\"train\" : None, \"test\" : None}\n",
    "tf_matrices = []\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "tf_fpr = []\n",
    "tf_tpr = []\n",
    "tf_thresh = []\n",
    "\n",
    "tf_auc = 0\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    tf_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    tf_ensemble.fit(x_train, y_train)\n",
    "    y_pred = tf_ensemble.predict(x_test)\n",
    "\n",
    "    tf_fpr.append(fpr)\n",
    "    tf_tpr.append(tpr)\n",
    "    tf_thresh.append(thresh)\n",
    "    tf_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    tf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = tf_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "tf_output[\"test\"] = [(test_total / run_count)]\n",
    "tf_output[\"train\"] = [(train_total / run_count)]\n",
    "tf_output = pd.DataFrame(tf_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "tf_matrices = np.mean(np.array(tf_matrices), axis=0)\n",
    "print(tf_matrices)\n",
    "\n",
    "tf_fpr = np.mean(np.array(tf_fpr), axis=0)\n",
    "tf_tpr = np.mean(np.array(tf_tpr), axis=0)\n",
    "tf_thresh = np.mean(np.array(tf_thresh), axis=0)\n",
    "\n",
    "tf_auc = tf_auc / float(run_count)\n",
    "\n",
    "\n",
    "plt.plot(tf_fpr, tf_tpr,\n",
    " lw=lw, label='Tf-Idf  (%0.2f)' % tf_auc)\n",
    "\n",
    "# write confusion matrix and save\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "riter = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "\n",
    "# write confusion matrix and save\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(comb_matrices).to_excel(writer, sheet_name=f\"tfidf_matrix\")\n",
    "\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n",
    "\n",
    "tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    combine accuracies into one table\n",
    "'''\n",
    "\n",
    "final_results = pd.concat((pol_output, tf_output, comb_output), axis=0)\n",
    "final_results.index = [\"Polarity\", \"Tf-Idf\", \"Polarity + Tf-Idf\"]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finally, save accuracy metrics to the spreadsheet\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "final_results.to_excel(writer, sheet_name=f\"accuracies\")\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "raw_fpr, raw_tpr, raw_thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "raw_roc_auc = metrics.auc(raw_fpr, raw_tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# save figure as PNG\n",
    "png = io.BytesIO()\n",
    "plt.savefig(png, format=\"png\")\n",
    "\n",
    "\n",
    "# write PNG to excel file\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "ws = book.active\n",
    "\n",
    "img = openpyxl.drawing.image.Image(png)\n",
    "img.anchor = \"A1\"\n",
    "ws.add_image(img)\n",
    "book.save(filename=EXCEL_FILE)\n",
    "plt.close()\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "counts[0] / sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
