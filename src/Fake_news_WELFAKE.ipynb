{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>title_tb_pol</th>\n",
       "      <th>title_tb_sub</th>\n",
       "      <th>title_vader_comp</th>\n",
       "      <th>title_vader_neg</th>\n",
       "      <th>title_vader_neu</th>\n",
       "      <th>title_vader_pos</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>52523</td>\n",
       "      <td>52523</td>\n",
       "      <td>OBAMA IGNORES PLANNED PARENTHOOD BABY PARTS HA...</td>\n",
       "      <td>Justice the Obama way Instead of investigating...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.405724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.4824</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>17817</td>\n",
       "      <td>17817</td>\n",
       "      <td>Cop Caught on His Own Body Camera Stealing Mon...</td>\n",
       "      <td>Home   Badge Abuse   Cop Caught on His Own Bod...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.402271</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>-0.8176</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>22879</td>\n",
       "      <td>22879</td>\n",
       "      <td>Congress s fight over Iran deal enters new phase</td>\n",
       "      <td>The Obama administration says new visa rules p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.411703</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>59352</td>\n",
       "      <td>59352</td>\n",
       "      <td>Spains Industry Minister Steps Down Over Panam...</td>\n",
       "      <td>MADRID     The Spanish minister of industry  e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092785</td>\n",
       "      <td>0.288384</td>\n",
       "      <td>-0.009596</td>\n",
       "      <td>0.371717</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>54521</td>\n",
       "      <td>54521</td>\n",
       "      <td>Almost  Missing After Boat Carrying Migrants S...</td>\n",
       "      <td>Get short URL     As many as  people are missi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.306061</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>-0.2280</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4066</th>\n",
       "      <td>33675</td>\n",
       "      <td>33675</td>\n",
       "      <td>HAMMER TIME  TRUMP POINTS OUT THE LIES BEHIND ...</td>\n",
       "      <td>This ad is spot on</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>42202</td>\n",
       "      <td>42202</td>\n",
       "      <td>PELOSI LOSES IT  Calls Tax Cuts End of the Wor...</td>\n",
       "      <td>Nancy Pelosi just got even more embarrassing t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>0.502619</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.6408</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>29210</td>\n",
       "      <td>29210</td>\n",
       "      <td>DEMOCRATS CAUGHT Paying Halfway House Patients...</td>\n",
       "      <td>A lawless party whose end always justifies the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>4713</td>\n",
       "      <td>4713</td>\n",
       "      <td>Magnates Twin Goals  Fighting Climate Change a...</td>\n",
       "      <td>MONTAUK  N  Y      On a sunny morning late thi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.446699</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4490</th>\n",
       "      <td>20304</td>\n",
       "      <td>20304</td>\n",
       "      <td>HEARTLESS DEMOCRATS Invite Illegals To Taunt T...</td>\n",
       "      <td>Jessica Davis  right  and Susan Oliver  left  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.355986</td>\n",
       "      <td>-0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.9436</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "2425         52523       52523   \n",
       "2290         17817       17817   \n",
       "853          22879       22879   \n",
       "2517         59352       59352   \n",
       "2577         54521       54521   \n",
       "...            ...         ...   \n",
       "4066         33675       33675   \n",
       "3484         42202       42202   \n",
       "2019         29210       29210   \n",
       "2147          4713        4713   \n",
       "4490         20304       20304   \n",
       "\n",
       "                                                  title  \\\n",
       "2425  OBAMA IGNORES PLANNED PARENTHOOD BABY PARTS HA...   \n",
       "2290  Cop Caught on His Own Body Camera Stealing Mon...   \n",
       "853    Congress s fight over Iran deal enters new phase   \n",
       "2517  Spains Industry Minister Steps Down Over Panam...   \n",
       "2577  Almost  Missing After Boat Carrying Migrants S...   \n",
       "...                                                 ...   \n",
       "4066  HAMMER TIME  TRUMP POINTS OUT THE LIES BEHIND ...   \n",
       "3484  PELOSI LOSES IT  Calls Tax Cuts End of the Wor...   \n",
       "2019  DEMOCRATS CAUGHT Paying Halfway House Patients...   \n",
       "2147  Magnates Twin Goals  Fighting Climate Change a...   \n",
       "4490  HEARTLESS DEMOCRATS Invite Illegals To Taunt T...   \n",
       "\n",
       "                                                   text  label  text_tb_pol  \\\n",
       "2425  Justice the Obama way Instead of investigating...      1     0.013468   \n",
       "2290  Home   Badge Abuse   Cop Caught on His Own Bod...      1     0.007261   \n",
       "853   The Obama administration says new visa rules p...      0     0.003346   \n",
       "2517  MADRID     The Spanish minister of industry  e...      0     0.092785   \n",
       "2577  Get short URL     As many as  people are missi...      1     0.100000   \n",
       "...                                                 ...    ...          ...   \n",
       "4066                                This ad is spot on       1     0.000000   \n",
       "3484  Nancy Pelosi just got even more embarrassing t...      1     0.189286   \n",
       "2019  A lawless party whose end always justifies the...      1     0.000000   \n",
       "2147  MONTAUK  N  Y      On a sunny morning late thi...      0     0.130400   \n",
       "4490  Jessica Davis  right  and Susan Oliver  left  ...      1     0.000193   \n",
       "\n",
       "      text_tb_sub  title_tb_pol  title_tb_sub  title_vader_comp  \\\n",
       "2425     0.405724      0.000000      0.000000           -0.4824   \n",
       "2290     0.402271      0.262500      0.525000           -0.8176   \n",
       "853      0.411703      0.136364      0.454545           -0.3818   \n",
       "2517     0.288384     -0.009596      0.371717            0.0000   \n",
       "2577     0.306061     -0.150000      0.025000           -0.2280   \n",
       "...           ...           ...           ...               ...   \n",
       "4066     0.000000      0.333333      0.766667            0.7954   \n",
       "3484     0.502619     -0.300000      0.100000           -0.6408   \n",
       "2019     0.000000      0.000000      0.000000            0.0000   \n",
       "2147     0.446699      0.136364      0.454545           -0.3612   \n",
       "4490     0.355986     -0.650000      0.700000           -0.9436   \n",
       "\n",
       "      title_vader_neg  title_vader_neu  title_vader_pos  text_vader_neg  \\\n",
       "2425            0.228            0.772            0.000           0.044   \n",
       "2290            0.459            0.541            0.000           0.162   \n",
       "853             0.245            0.755            0.000           0.121   \n",
       "2517            0.000            1.000            0.000           0.088   \n",
       "2577            0.175            0.825            0.000           0.075   \n",
       "...               ...              ...              ...             ...   \n",
       "4066            0.130            0.516            0.354           0.000   \n",
       "3484            0.368            0.632            0.000           0.052   \n",
       "2019            0.000            1.000            0.000           0.102   \n",
       "2147            0.161            0.839            0.000           0.062   \n",
       "4490            0.444            0.511            0.045           0.116   \n",
       "\n",
       "      text_vader_neu  text_vader_pos  flag  \n",
       "2425           0.851           0.104     1  \n",
       "2290           0.797           0.041     1  \n",
       "853            0.800           0.079     0  \n",
       "2517           0.846           0.066     0  \n",
       "2577           0.889           0.035     1  \n",
       "...              ...             ...   ...  \n",
       "4066           1.000           0.000     1  \n",
       "3484           0.791           0.157     1  \n",
       "2019           0.753           0.144     1  \n",
       "2147           0.800           0.138     0  \n",
       "4490           0.827           0.057     1  \n",
       "\n",
       "[5000 rows x 17 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    WELFAKE\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/WELFAKE_PROCESSED.csv\")\n",
    "data[\"flag\"] = data[\"label\"]\n",
    "data = data.sample(5000)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Add tf-idf vectorizer\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "def tf_idf_vectorize(df: pd.DataFrame, corpus: pd.Series, vocabulary: list[str]) -> tuple[list[str], pd.DataFrame]:\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stop_words, max_features=500, ngram_range=(1,3), vocabulary=vocabulary)\n",
    "    features = vectorizer.fit_transform(corpus).toarray()\n",
    "    names = vectorizer.get_feature_names_out()\n",
    "    headers = [f\"__word{i}\" for i in range(len(names))]\n",
    "    feature_frame = pd.DataFrame(features, columns=headers)\n",
    "    #final = pd.concat([df, feature_frame], axis=1)\n",
    "    return (names, feature_frame)\n",
    "\n",
    "\n",
    "def get_full_vocabulary(corpus: pd.Series) -> list[str]:\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stopwords.words(\"english\"), max_features=500, ngram_range=(1,3))\n",
    "    vectorizer.fit_transform(corpus).toarray()\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "def add_tf_idf_vector(x: pd.DataFrame, partial_corpus: pd.Series, full_corpus: pd.Series) -> pd.DataFrame:\n",
    "    temp = pd.concat((x, partial_corpus), axis=1).reset_index()\n",
    "    # first, we need a vocabulary from the entire dataset\n",
    "    vocabulary = get_full_vocabulary(full_corpus)\n",
    "\n",
    "    tf_idf_vector = tf_idf_vectorize(temp, temp[partial_corpus.name], vocabulary=vocabulary)[1].reset_index()\n",
    "    temp = temp.reset_index()\n",
    "    temp = pd.concat((temp, tf_idf_vector), axis=1).drop([partial_corpus.name, \"index\"], axis=1)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "'''\n",
    "    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"]\n",
    "\n",
    "filtered[\"corpus\"] = filtered.apply(lambda x: \" \".join([x[\"title\"], x[\"text\"]]), axis=1)\n",
    "\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]]\n",
    "\n",
    "# dataframe to store accuracies for NN and log regression\n",
    "#accuracy_df = pd.DataFrame(columns=[\"polarity\",\n",
    "#               \"tfidf\",\n",
    "#               \"combined\"])\n",
    "\n",
    "\n",
    "EXCEL_FILE = r\"../data/Des_fake_news/Sentiment_Analysis_Results/WELFAKE_RESULTS.xlsx\"\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "1\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "2\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "3\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "4\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "Train accuracy on 5-fold cross-validation: 0.9952500000000001\n",
      "Test accuracy on 5-fold cross-validation: 0.9184000000000001\n",
      "Average confusion matrix:\n",
      "[[441.4  44.4]\n",
      " [ 37.2 477. ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99525</td>\n",
       "      <td>0.9184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train    test\n",
       "0  0.99525  0.9184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY + TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "comb_output = {\"train\" : None, \"test\" : None}\n",
    "comb_matrices = []\n",
    "\n",
    "\n",
    "comb_fpr = []\n",
    "comb_tpr = []\n",
    "comb_thresh = []\n",
    "\n",
    "comb_auc = 0\n",
    "\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"])\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    comb_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    comb_ensemble.fit(x_train, y_train)\n",
    "    y_pred = comb_ensemble.predict(x_test)\n",
    "\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    comb_fpr.append(fpr)\n",
    "    comb_tpr.append(tpr)\n",
    "    comb_thresh.append(thresh)\n",
    "    comb_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    comb_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = comb_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "comb_output[\"test\"] = [(test_total / run_count)]\n",
    "comb_output[\"train\"] = [(train_total / run_count)]\n",
    "comb_output = pd.DataFrame(comb_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "comb_matrices = np.mean(np.array(comb_matrices), axis=0)\n",
    "print(comb_matrices)\n",
    "\n",
    "\n",
    "comb_fpr = np.mean(np.array(comb_fpr), axis=0)\n",
    "comb_tpr = np.mean(np.array(comb_tpr), axis=0)\n",
    "comb_thresh = np.mean(np.array(comb_thresh), axis=0)\n",
    "\n",
    "comb_auc = comb_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ensemble fitting\n",
      "1\n",
      "ensemble fitting\n",
      "2\n",
      "ensemble fitting\n",
      "3\n",
      "ensemble fitting\n",
      "4\n",
      "ensemble fitting\n",
      "Train accuracy on 5-fold cross-validation: 0.88695\n",
      "Test accuracy on 5-fold cross-validation: 0.7023999999999999\n",
      "Average confusion matrix:\n",
      "[[341.4 144.4]\n",
      " [153.2 361. ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.88695</td>\n",
       "      <td>0.7024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train    test\n",
       "0  0.88695  0.7024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "pol_output = {\"train\" : None, \"test\" : None}\n",
    "pol_matrices = []\n",
    "\n",
    "\n",
    "pol_fpr = []\n",
    "pol_tpr = []\n",
    "pol_thresh = []\n",
    "\n",
    "pol_auc = 0\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "  \n",
    "    x_train = x.iloc[train_index]\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    x_test = x.iloc[test_index]\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    pol_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    pol_ensemble.fit(x_train, y_train)\n",
    "    y_pred = pol_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    pol_fpr.append(fpr)\n",
    "    pol_tpr.append(tpr)\n",
    "    pol_thresh.append(thresh)\n",
    "    pol_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    pol_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = pol_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "pol_output[\"test\"] = [(test_total / run_count)]\n",
    "pol_output[\"train\"] = [(train_total / run_count)]\n",
    "pol_output = pd.DataFrame(pol_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "pol_matrices = np.mean(np.array(pol_matrices), axis=0)\n",
    "print(pol_matrices)\n",
    "\n",
    "pol_fpr = np.mean(np.array(pol_fpr), axis=0)\n",
    "pol_tpr = np.mean(np.array(pol_tpr), axis=0)\n",
    "pol_thresh = np.mean(np.array(pol_thresh), axis=0)\n",
    "\n",
    "pol_auc = pol_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pol_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "1\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "2\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "3\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "4\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "Train accuracy on 5-fold cross-validation: 0.99445\n",
      "Test accuracy on 5-fold cross-validation: 0.9196\n",
      "Average confusion matrix:\n",
      "[[441.4  44.4]\n",
      " [ 36.  478.2]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99445</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train    test\n",
       "0  0.99445  0.9196"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "tf_output = {\"train\" : None, \"test\" : None}\n",
    "tf_matrices = []\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "tf_fpr = []\n",
    "tf_tpr = []\n",
    "tf_thresh = []\n",
    "\n",
    "tf_auc = 0\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    tf_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    tf_ensemble.fit(x_train, y_train)\n",
    "    y_pred = tf_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    tf_fpr.append(fpr)\n",
    "    tf_tpr.append(tpr)\n",
    "    tf_thresh.append(thresh)\n",
    "    tf_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    tf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = tf_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "tf_output[\"test\"] = [(test_total / run_count)]\n",
    "tf_output[\"train\"] = [(train_total / run_count)]\n",
    "tf_output = pd.DataFrame(tf_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "tf_matrices = np.mean(np.array(tf_matrices), axis=0)\n",
    "print(tf_matrices)\n",
    "\n",
    "tf_fpr = np.mean(np.array(tf_fpr), axis=0)\n",
    "tf_tpr = np.mean(np.array(tf_tpr), axis=0)\n",
    "tf_thresh = np.mean(np.array(tf_thresh), axis=0)\n",
    "\n",
    "tf_auc = tf_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Polarity</th>\n",
       "      <td>0.88695</td>\n",
       "      <td>0.7024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tf-Idf</th>\n",
       "      <td>0.99445</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polarity + Tf-Idf</th>\n",
       "      <td>0.99525</td>\n",
       "      <td>0.9184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train    test\n",
       "Polarity           0.88695  0.7024\n",
       "Tf-Idf             0.99445  0.9196\n",
       "Polarity + Tf-Idf  0.99525  0.9184"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    combine accuracies into one table\n",
    "'''\n",
    "\n",
    "final_results = pd.concat((pol_output, tf_output, comb_output), axis=0)\n",
    "final_results.index = [\"Polarity\", \"Tf-Idf\", \"Polarity + Tf-Idf\"]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\desmo\\AppData\\Local\\Temp\\ipykernel_8452\\3534906820.py:10: FutureWarning: Setting the `book` attribute is not part of the public API, usage can give unexpected or corrupted results and will be removed in a future version\n",
      "  writer.book = book\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Finally, save accuracy metrics to the spreadsheet\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "final_results.to_excel(writer, sheet_name=f\"accuracies\")\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(pol_fpr, pol_tpr,\n",
    " lw=lw, label='Polarity: (%0.2f)' % pol_auc)\n",
    "plt.plot(tf_fpr, tf_tpr,\n",
    " lw=lw, label='Tf-Idf: (%0.2f)' % tf_auc)\n",
    "plt.plot(comb_fpr, comb_tpr,\n",
    " lw=lw, label='Polarity + Tf-Idf: (%0.2f)' % comb_auc)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# save figure as PNG\n",
    "png = io.BytesIO()\n",
    "plt.savefig(png, format=\"png\")\n",
    "\n",
    "\n",
    "# write PNG to excel file\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "ws = book.active\n",
    "\n",
    "img = openpyxl.drawing.image.Image(png)\n",
    "img.anchor = \"A1\"\n",
    "ws.add_image(img)\n",
    "book.save(filename=EXCEL_FILE)\n",
    "plt.close()\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
