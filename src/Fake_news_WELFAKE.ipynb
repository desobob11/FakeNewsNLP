{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>title_tb_pol</th>\n",
       "      <th>title_tb_sub</th>\n",
       "      <th>title_vader_comp</th>\n",
       "      <th>title_vader_neg</th>\n",
       "      <th>title_vader_neu</th>\n",
       "      <th>title_vader_pos</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>18775</td>\n",
       "      <td>18775</td>\n",
       "      <td>Russia Brags About Helping Trump Win As Our E...</td>\n",
       "      <td>Russia and Vladimir Putin got what they wanted...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095177</td>\n",
       "      <td>0.379331</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>48322</td>\n",
       "      <td>48322</td>\n",
       "      <td>As Syria war tightens  U S  and Russia militar...</td>\n",
       "      <td>AL UDEID AIR BASE  Qatar  Reuters    Even as t...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.291768</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>58829</td>\n",
       "      <td>58829</td>\n",
       "      <td>Debunked  The Photo Of Obama With A Speech Bal...</td>\n",
       "      <td>Email \\nIn an age where information can be spr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187857</td>\n",
       "      <td>0.546633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>67109</td>\n",
       "      <td>67109</td>\n",
       "      <td>Top US Spy Agency Refuses to Endorse CIAs Russ...</td>\n",
       "      <td>st Century Wire says If anyone still thinks th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059429</td>\n",
       "      <td>0.501429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>32457</td>\n",
       "      <td>32457</td>\n",
       "      <td>Alec Baldwin Joins Anti Trump Protest  Gives ...</td>\n",
       "      <td>Over the next few days  America  and the world...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.394889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8331</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>25563</td>\n",
       "      <td>25563</td>\n",
       "      <td>Behind anti Trump protests  worries that Ameri...</td>\n",
       "      <td>For many Americans who have long felt threaten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066157</td>\n",
       "      <td>0.441716</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-0.5719</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1974</td>\n",
       "      <td>1974</td>\n",
       "      <td>American Express disowns Pink Floyd singer Rog...</td>\n",
       "      <td>American Express disowns Pink Floyd singer Rog...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103821</td>\n",
       "      <td>0.308635</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>71792</td>\n",
       "      <td>71792</td>\n",
       "      <td>Justice Department antitrust nominee Makan Del...</td>\n",
       "      <td>WASHINGTON  Reuters    The confirmation testim...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002101</td>\n",
       "      <td>0.236975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>31581</td>\n",
       "      <td>31581</td>\n",
       "      <td>Who Will Tell the Story of Slavery    The New ...</td>\n",
       "      <td>RICHMOND  VA      Here in the onetime capital ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039572</td>\n",
       "      <td>0.376275</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.7003</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>19325</td>\n",
       "      <td>19325</td>\n",
       "      <td>The Circus of Liars   America s Three Rings of...</td>\n",
       "      <td>Wed   Oct    UTC  Jen Psaki President Obama ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.051658</td>\n",
       "      <td>0.472647</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.8316</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0  \\\n",
       "4967         18775       18775   \n",
       "401          48322       48322   \n",
       "2710         58829       58829   \n",
       "2346         67109       67109   \n",
       "1176         32457       32457   \n",
       "100          25563       25563   \n",
       "90            1974        1974   \n",
       "2047         71792       71792   \n",
       "2533         31581       31581   \n",
       "317          19325       19325   \n",
       "\n",
       "                                                  title  \\\n",
       "4967   Russia Brags About Helping Trump Win As Our E...   \n",
       "401   As Syria war tightens  U S  and Russia militar...   \n",
       "2710  Debunked  The Photo Of Obama With A Speech Bal...   \n",
       "2346  Top US Spy Agency Refuses to Endorse CIAs Russ...   \n",
       "1176   Alec Baldwin Joins Anti Trump Protest  Gives ...   \n",
       "100   Behind anti Trump protests  worries that Ameri...   \n",
       "90    American Express disowns Pink Floyd singer Rog...   \n",
       "2047  Justice Department antitrust nominee Makan Del...   \n",
       "2533  Who Will Tell the Story of Slavery    The New ...   \n",
       "317   The Circus of Liars   America s Three Rings of...   \n",
       "\n",
       "                                                   text  label  text_tb_pol  \\\n",
       "4967  Russia and Vladimir Putin got what they wanted...      1     0.095177   \n",
       "401   AL UDEID AIR BASE  Qatar  Reuters    Even as t...      0    -0.000174   \n",
       "2710  Email \\nIn an age where information can be spr...      1     0.187857   \n",
       "2346  st Century Wire says If anyone still thinks th...      1     0.059429   \n",
       "1176  Over the next few days  America  and the world...      1     0.027786   \n",
       "100   For many Americans who have long felt threaten...      0     0.066157   \n",
       "90    American Express disowns Pink Floyd singer Rog...      1     0.103821   \n",
       "2047  WASHINGTON  Reuters    The confirmation testim...      0    -0.002101   \n",
       "2533  RICHMOND  VA      Here in the onetime capital ...      0     0.039572   \n",
       "317   Wed   Oct    UTC  Jen Psaki President Obama ho...      1     0.051658   \n",
       "\n",
       "      text_tb_sub  title_tb_pol  title_tb_sub  title_vader_comp  \\\n",
       "4967     0.379331      0.400000      0.200000            0.1280   \n",
       "401      0.291768     -0.100000      0.100000           -0.5994   \n",
       "2710     0.546633      0.000000      0.000000            0.0000   \n",
       "2346     0.501429      0.125000      0.291667            0.2023   \n",
       "1176     0.394889      0.000000      0.000000           -0.8331   \n",
       "100      0.441716     -0.400000      0.700000           -0.5719   \n",
       "90       0.308635     -0.050000      0.150000            0.0000   \n",
       "2047     0.236975      0.000000      0.000000            0.3612   \n",
       "2533     0.376275      0.136364      0.454545           -0.7003   \n",
       "317      0.472647     -1.000000      1.000000           -0.8316   \n",
       "\n",
       "      title_vader_neg  title_vader_neu  title_vader_pos  text_vader_neg  \\\n",
       "4967            0.256            0.465            0.279           0.100   \n",
       "401             0.281            0.719            0.000           0.066   \n",
       "2710            0.000            1.000            0.000           0.052   \n",
       "2346            0.119            0.670            0.211           0.113   \n",
       "1176            0.424            0.576            0.000           0.098   \n",
       "100             0.405            0.462            0.133           0.101   \n",
       "90              0.000            1.000            0.000           0.071   \n",
       "2047            0.154            0.569            0.276           0.067   \n",
       "2533            0.324            0.676            0.000           0.083   \n",
       "317             0.464            0.536            0.000           0.140   \n",
       "\n",
       "      text_vader_neu  text_vader_pos  flag  \n",
       "4967           0.787           0.113     1  \n",
       "401            0.899           0.036     0  \n",
       "2710           0.801           0.148     1  \n",
       "2346           0.784           0.102     1  \n",
       "1176           0.814           0.088     1  \n",
       "100            0.800           0.099     0  \n",
       "90             0.865           0.064     1  \n",
       "2047           0.863           0.070     0  \n",
       "2533           0.830           0.087     0  \n",
       "317            0.765           0.095     1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    WELFAKE\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/WELFAKE_PROCESSED.csv\")\n",
    "data[\"flag\"] = data[\"label\"]\n",
    "data = data.sample(10)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Add tf-idf vectorizer\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_tf_idf_vector(x: pd.DataFrame, corpus: pd.Series) -> tuple[pd.DataFrame, list[str], TfidfVectorizer]:\n",
    "    #temp = pd.concat((x, corpus), axis=1).reset_index()\n",
    "\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stop_words, max_features=500, ngram_range=(1,3))\n",
    "    tf_idf_features = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "    names = vectorizer.get_feature_names_out()\n",
    "    headers = [f\"__word{i}\" for i in range(len(names))]\n",
    "    feature_frame = pd.DataFrame(tf_idf_features, columns=headers).reset_index()\n",
    "    #all_features = pd.concat((x.reset_index(), feature_frame), axis=1).reset_index()\n",
    "    return (feature_frame.drop([\"level_0\", \"index\"], axis=1), names, vectorizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "'''\n",
    "    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"]\n",
    "\n",
    "filtered[\"corpus\"] = filtered.apply(lambda x: \" \".join([x[\"title\"], x[\"text\"]]), axis=1)\n",
    "\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\t\"title_tb_pol\",\t\"title_tb_sub\",\t\"title_vader_comp\",\t\"title_vader_neg\",\t\n",
    "              \"title_vader_neu\",\t\"title_vader_pos\",\t\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]]\n",
    "\n",
    "\n",
    "\n",
    "EXCEL_FILE = r\"../data/Des_fake_news/Sentiment_Analysis_Results/WELFAKE_RESULTS.xlsx\"\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "1\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "2\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "3\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "4\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "Train accuracy on 5-fold cross-validation: 0.99595\n",
      "Test accuracy on 5-fold cross-validation: 0.922\n",
      "Average confusion matrix:\n",
      "[[443.2  42.6]\n",
      " [ 35.4 478.8]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99595</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     train   test\n",
       "0  0.99595  0.922"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY + TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "comb_output = {\"train\" : None, \"test\" : None}\n",
    "comb_matrices = []\n",
    "\n",
    "\n",
    "comb_fpr = []\n",
    "comb_tpr = []\n",
    "comb_thresh = []\n",
    "\n",
    "comb_auc = 0\n",
    "\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "x_train = None\n",
    "x_test = None\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    tf_idf_training, names, vectorizer = get_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = pd.DataFrame(vectorizer.transform(filtered[\"corpus\"].iloc[test_index]).toarray(), columns=[f\"__word{i}\" for i in range(len(names))])\n",
    "    x_test = pd.concat((x.iloc[test_index].reset_index(), x_test), axis=1).drop(\"index\", axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    comb_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    comb_ensemble.fit(x_train, y_train)\n",
    "    y_pred = comb_ensemble.predict(x_test)\n",
    "\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    comb_fpr.append(fpr)\n",
    "    comb_tpr.append(tpr)\n",
    "    comb_thresh.append(thresh)\n",
    "    comb_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    comb_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = comb_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "comb_output[\"test\"] = [(test_total / run_count)]\n",
    "comb_output[\"train\"] = [(train_total / run_count)]\n",
    "comb_output = pd.DataFrame(comb_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "comb_matrices = np.mean(np.array(comb_matrices), axis=0)\n",
    "print(comb_matrices)\n",
    "\n",
    "\n",
    "comb_fpr = np.mean(np.array(comb_fpr), axis=0)\n",
    "comb_tpr = np.mean(np.array(comb_tpr), axis=0)\n",
    "comb_thresh = np.mean(np.array(comb_thresh), axis=0)\n",
    "\n",
    "comb_auc = comb_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_test\n",
    "\n",
    "comb_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "pol_output = {\"train\" : None, \"test\" : None}\n",
    "pol_matrices = []\n",
    "\n",
    "\n",
    "pol_fpr = []\n",
    "pol_tpr = []\n",
    "pol_thresh = []\n",
    "\n",
    "pol_auc = 0\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train, names, vectorizer = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = pd.DataFrame(vectorizer.transform(filtered[\"corpus\"].iloc[test_index]).toarray(), columns=[f\"__word{i}\" for i in range(len(names))])\n",
    "    x_test = pd.concat((x.iloc[test_index].reset_index(), x_test), axis=1).drop(\"index\", axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    pol_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    pol_ensemble.fit(x_train, y_train)\n",
    "    y_pred = pol_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    pol_fpr.append(fpr)\n",
    "    pol_tpr.append(tpr)\n",
    "    pol_thresh.append(thresh)\n",
    "    pol_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    pol_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = pol_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "pol_output[\"test\"] = [(test_total / run_count)]\n",
    "pol_output[\"train\"] = [(train_total / run_count)]\n",
    "pol_output = pd.DataFrame(pol_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "pol_matrices = np.mean(np.array(pol_matrices), axis=0)\n",
    "print(pol_matrices)\n",
    "\n",
    "pol_fpr = np.mean(np.array(pol_fpr), axis=0)\n",
    "pol_tpr = np.mean(np.array(pol_tpr), axis=0)\n",
    "pol_thresh = np.mean(np.array(pol_thresh), axis=0)\n",
    "\n",
    "pol_auc = pol_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pol_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "tf_output = {\"train\" : None, \"test\" : None}\n",
    "tf_matrices = []\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "tf_fpr = []\n",
    "tf_tpr = []\n",
    "tf_thresh = []\n",
    "\n",
    "tf_auc = 0\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "     scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train, names, vectorizer = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    \n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = pd.DataFrame(vectorizer.transform(filtered[\"corpus\"].iloc[test_index]).toarray(), columns=[f\"__word{i}\" for i in range(len(names))])\n",
    "    x_test = pd.concat((x.iloc[test_index].reset_index(), x_test), axis=1).drop(\"index\", axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "   \n",
    "    \n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    tf_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    tf_ensemble.fit(x_train, y_train)\n",
    "    y_pred = tf_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    tf_fpr.append(fpr)\n",
    "    tf_tpr.append(tpr)\n",
    "    tf_thresh.append(thresh)\n",
    "    tf_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    tf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = tf_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "tf_output[\"test\"] = [(test_total / run_count)]\n",
    "tf_output[\"train\"] = [(train_total / run_count)]\n",
    "tf_output = pd.DataFrame(tf_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "tf_matrices = np.mean(np.array(tf_matrices), axis=0)\n",
    "print(tf_matrices)\n",
    "\n",
    "tf_fpr = np.mean(np.array(tf_fpr), axis=0)\n",
    "tf_tpr = np.mean(np.array(tf_tpr), axis=0)\n",
    "tf_thresh = np.mean(np.array(tf_thresh), axis=0)\n",
    "\n",
    "tf_auc = tf_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    combine accuracies into one table\n",
    "'''\n",
    "\n",
    "final_results = pd.concat((pol_output, tf_output, comb_output), axis=0)\n",
    "final_results.index = [\"Polarity\", \"Tf-Idf\", \"Polarity + Tf-Idf\"]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finally, save accuracy metrics to the spreadsheet\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "final_results.to_excel(writer, sheet_name=f\"accuracies\")\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(pol_fpr, pol_tpr,\n",
    " lw=lw, label='Polarity: (%0.2f)' % pol_auc)\n",
    "plt.plot(tf_fpr, tf_tpr,\n",
    " lw=lw, label='Tf-Idf: (%0.2f)' % tf_auc)\n",
    "plt.plot(comb_fpr, comb_tpr,\n",
    " lw=lw, label='Polarity + Tf-Idf: (%0.2f)' % comb_auc)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# save figure as PNG\n",
    "png = io.BytesIO()\n",
    "plt.savefig(png, format=\"png\")\n",
    "\n",
    "\n",
    "# write PNG to excel file\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "ws = book.active\n",
    "\n",
    "img = openpyxl.drawing.image.Image(png)\n",
    "img.anchor = \"A1\"\n",
    "ws.add_image(img)\n",
    "book.save(filename=EXCEL_FILE)\n",
    "plt.close()\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
