{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job title</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barelytrues</th>\n",
       "      <th>...</th>\n",
       "      <th>text_tb_pol</th>\n",
       "      <th>text_tb_sub</th>\n",
       "      <th>title_tb_pol</th>\n",
       "      <th>title_tb_sub</th>\n",
       "      <th>title_vader_neg</th>\n",
       "      <th>title_vader_neu</th>\n",
       "      <th>title_vader_pos</th>\n",
       "      <th>text_vader_neg</th>\n",
       "      <th>text_vader_neu</th>\n",
       "      <th>text_vader_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>2718</td>\n",
       "      <td>4594.json</td>\n",
       "      <td>0</td>\n",
       "      <td>Says Rick Perry co chaired Al Gores campaign f...</td>\n",
       "      <td>candidates biography elections</td>\n",
       "      <td>michele-bachmann</td>\n",
       "      <td>Congresswoman</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>republican</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>4121</td>\n",
       "      <td>1068.json</td>\n",
       "      <td>1</td>\n",
       "      <td>Every year tobacco kills more Americans than d...</td>\n",
       "      <td>consumer safety</td>\n",
       "      <td>george-will</td>\n",
       "      <td>Columnist</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>columnist</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>8205</td>\n",
       "      <td>7662.json</td>\n",
       "      <td>0</td>\n",
       "      <td>Says Texas school systems lose  days a year on...</td>\n",
       "      <td>education</td>\n",
       "      <td>david-dewhurst</td>\n",
       "      <td>Lieutenant governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3822</th>\n",
       "      <td>3822</td>\n",
       "      <td>5981.json</td>\n",
       "      <td>0</td>\n",
       "      <td>On transportation financing</td>\n",
       "      <td>state budget transportation</td>\n",
       "      <td>chris-christie</td>\n",
       "      <td>Governor of New Jersey</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>republican</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6859</th>\n",
       "      <td>6859</td>\n",
       "      <td>5504.json</td>\n",
       "      <td>0</td>\n",
       "      <td>Says Barack Obama promised gasoline at    a ga...</td>\n",
       "      <td>energy gas prices transportation</td>\n",
       "      <td>lenny-curry</td>\n",
       "      <td>chairman of the Republican Party of Florida</td>\n",
       "      <td>Florida</td>\n",
       "      <td>republican</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4175</td>\n",
       "      <td>608.json</td>\n",
       "      <td>1</td>\n",
       "      <td>We could save all the oil that they re talking...</td>\n",
       "      <td>energy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>7342</td>\n",
       "      <td>11634.json</td>\n",
       "      <td>1</td>\n",
       "      <td>Twenty five percent of our kids in foster care...</td>\n",
       "      <td>children drugs poverty</td>\n",
       "      <td>vicky-hartzler</td>\n",
       "      <td>U.S. Representative</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>918</td>\n",
       "      <td>1978.json</td>\n",
       "      <td>0</td>\n",
       "      <td>On whether a U S  Supreme Court nominee should...</td>\n",
       "      <td>kagan nomination supreme court</td>\n",
       "      <td>elena-kagan</td>\n",
       "      <td>U.S. solicitor general</td>\n",
       "      <td>New York</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>5762</td>\n",
       "      <td>3441.json</td>\n",
       "      <td>1</td>\n",
       "      <td>Lake Erie supports nearly  percent of Ohios jo...</td>\n",
       "      <td>economy environment federal budget tourism</td>\n",
       "      <td>betty-sutton</td>\n",
       "      <td>U.S. representative from Ohio's 13th District</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11972.json</td>\n",
       "      <td>1</td>\n",
       "      <td>Building a wall on the U S  Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0          id  class  \\\n",
       "2718        2718   4594.json      0   \n",
       "4121        4121   1068.json      1   \n",
       "8205        8205   7662.json      0   \n",
       "3822        3822   5981.json      0   \n",
       "6859        6859   5504.json      0   \n",
       "...          ...         ...    ...   \n",
       "4175        4175    608.json      1   \n",
       "7342        7342  11634.json      1   \n",
       "918          918   1978.json      0   \n",
       "5762        5762   3441.json      1   \n",
       "0              0  11972.json      1   \n",
       "\n",
       "                                                   text  \\\n",
       "2718  Says Rick Perry co chaired Al Gores campaign f...   \n",
       "4121  Every year tobacco kills more Americans than d...   \n",
       "8205  Says Texas school systems lose  days a year on...   \n",
       "3822                        On transportation financing   \n",
       "6859  Says Barack Obama promised gasoline at    a ga...   \n",
       "...                                                 ...   \n",
       "4175  We could save all the oil that they re talking...   \n",
       "7342  Twenty five percent of our kids in foster care...   \n",
       "918   On whether a U S  Supreme Court nominee should...   \n",
       "5762  Lake Erie supports nearly  percent of Ohios jo...   \n",
       "0     Building a wall on the U S  Mexico border will...   \n",
       "\n",
       "                                           title           speaker  \\\n",
       "2718              candidates biography elections  michele-bachmann   \n",
       "4121                             consumer safety       george-will   \n",
       "8205                                   education    david-dewhurst   \n",
       "3822                 state budget transportation    chris-christie   \n",
       "6859            energy gas prices transportation       lenny-curry   \n",
       "...                                          ...               ...   \n",
       "4175                                      energy      barack-obama   \n",
       "7342                      children drugs poverty    vicky-hartzler   \n",
       "918               kagan nomination supreme court       elena-kagan   \n",
       "5762  economy environment federal budget tourism      betty-sutton   \n",
       "0                                    immigration        rick-perry   \n",
       "\n",
       "                                          job title       state       party  \\\n",
       "2718                                  Congresswoman   Minnesota  republican   \n",
       "4121                                      Columnist    Maryland   columnist   \n",
       "8205                            Lieutenant governor       Texas  republican   \n",
       "3822                         Governor of New Jersey  New Jersey  republican   \n",
       "6859    chairman of the Republican Party of Florida     Florida  republican   \n",
       "...                                             ...         ...         ...   \n",
       "4175                                      President    Illinois    democrat   \n",
       "7342                            U.S. Representative    Missouri  republican   \n",
       "918                          U.S. solicitor general    New York    democrat   \n",
       "5762  U.S. representative from Ohio's 13th District        Ohio    democrat   \n",
       "0                                          Governor       Texas  republican   \n",
       "\n",
       "      barelytrues  ...  text_tb_pol  text_tb_sub  title_tb_pol  title_tb_sub  \\\n",
       "2718            8  ...         0.00     0.000000           0.0           0.0   \n",
       "4121            7  ...         0.50     0.500000           0.0           0.0   \n",
       "8205            8  ...         0.00     0.000000           0.0           0.0   \n",
       "3822           10  ...         0.00     0.000000           0.0           0.0   \n",
       "6859            2  ...         0.00     0.000000           0.0           0.0   \n",
       "...           ...  ...          ...          ...           ...           ...   \n",
       "4175           70  ...         0.00     0.076923           0.0           0.0   \n",
       "7342            1  ...         0.00     0.000000           0.0           0.0   \n",
       "918             0  ...         0.00     0.000000           0.0           0.0   \n",
       "5762            0  ...         0.05     0.200000           0.0           0.0   \n",
       "0              30  ...         0.00     0.000000           0.0           0.0   \n",
       "\n",
       "     title_vader_neg  title_vader_neu  title_vader_pos  text_vader_neg  \\\n",
       "2718           0.000            1.000            0.000           0.000   \n",
       "4121           0.000            0.263            0.737           0.492   \n",
       "8205           0.000            1.000            0.000           0.231   \n",
       "3822           0.000            1.000            0.000           0.000   \n",
       "6859           0.000            0.588            0.412           0.000   \n",
       "...              ...              ...              ...             ...   \n",
       "4175           0.000            0.000            1.000           0.000   \n",
       "7342           0.623            0.377            0.000           0.000   \n",
       "918            0.000            0.455            0.545           0.000   \n",
       "5762           0.000            1.000            0.000           0.000   \n",
       "0              0.000            1.000            0.000           0.000   \n",
       "\n",
       "      text_vader_neu  text_vader_pos  \n",
       "2718           1.000           0.000  \n",
       "4121           0.508           0.000  \n",
       "8205           0.769           0.000  \n",
       "3822           1.000           0.000  \n",
       "6859           0.737           0.263  \n",
       "...              ...             ...  \n",
       "4175           0.887           0.113  \n",
       "7342           0.842           0.158  \n",
       "918            0.783           0.217  \n",
       "5762           0.857           0.143  \n",
       "0              1.000           0.000  \n",
       "\n",
       "[5000 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from textblob import *\n",
    "import nltk\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import *\n",
    "'''\n",
    "    LIAR\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"../data/Des_fake_news/LIAR_PROCESSED.csv\")\n",
    "data[\"flag\"] = data[\"class\"]\n",
    "data = data.sample(5000)\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Add tf-idf vectorizer\n",
    "'''\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "def tf_idf_vectorize(df: pd.DataFrame, corpus: pd.Series, vocabulary: list[str]) -> tuple[list[str], pd.DataFrame]:\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stop_words, max_features=500, ngram_range=(1,3), vocabulary=vocabulary)\n",
    "    features = vectorizer.fit_transform(corpus).toarray()\n",
    "    names = vectorizer.get_feature_names_out()\n",
    "    headers = [f\"__word{i}\" for i in range(len(names))]\n",
    "    feature_frame = pd.DataFrame(features, columns=headers)\n",
    "    #final = pd.concat([df, feature_frame], axis=1)\n",
    "    return (names, feature_frame)\n",
    "\n",
    "\n",
    "def get_full_vocabulary(corpus: pd.Series) -> list[str]:\n",
    "    vectorizer = TfidfVectorizer(strip_accents=\"ascii\", lowercase=True, stop_words=stopwords.words(\"english\"), max_features=500, ngram_range=(1,3))\n",
    "    vectorizer.fit_transform(corpus).toarray()\n",
    "    return vectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "def add_tf_idf_vector(x: pd.DataFrame, partial_corpus: pd.Series, full_corpus: pd.Series) -> pd.DataFrame:\n",
    "    temp = pd.concat((x, partial_corpus), axis=1).reset_index()\n",
    "    # first, we need a vocabulary from the entire dataset\n",
    "    vocabulary = get_full_vocabulary(full_corpus)\n",
    "\n",
    "    tf_idf_vector = tf_idf_vectorize(temp, temp[partial_corpus.name], vocabulary=vocabulary)[1].reset_index()\n",
    "    temp = temp.reset_index()\n",
    "    temp = pd.concat((temp, tf_idf_vector), axis=1).drop([partial_corpus.name, \"index\"], axis=1)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m'''Drop NA'''\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m filtered \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      9\u001b[0m classes \u001b[38;5;241m=\u001b[39m filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflag\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorpus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m filtered[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from openpyxl import load_workbook, Workbook\n",
    "\n",
    "'''\n",
    "    Define filtered dataset, classes, features, dataframe for model accuracies, and excel file for results\n",
    "'''\n",
    "\n",
    "'''Drop NA'''\n",
    "filtered = data.dropna()\n",
    "classes = filtered[\"flag\"]\n",
    "\n",
    "filtered[\"corpus\"] = filtered[\"text\"]\n",
    "\n",
    "\n",
    "# raw polarity and subjectivity scores from Textblob, Vader\n",
    "features = filtered[[\"text_tb_pol\",\t\"text_tb_sub\",\"text_vader_neg\",\t\"text_vader_neu\",\t\"text_vader_pos\"]]\n",
    "\n",
    "# dataframe to store accuracies for NN and log regression\n",
    "#accuracy_df = pd.DataFrame(columns=[\"polarity\",\n",
    "#               \"tfidf\",\n",
    "#               \"combined\"])\n",
    "\n",
    "\n",
    "EXCEL_FILE = r\"../data/Des_fake_news/Sentiment_Analysis_Results/LIAR_RESULTS.xlsx\"\n",
    "# overwrite book if exists\n",
    "book = Workbook()\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "1\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "2\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "3\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n",
      "4\n",
      "tf_idf training\n",
      "tf_idf testing\n",
      "ensemble fitting\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    POLARITY + TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "comb_output = {\"train\" : None, \"test\" : None}\n",
    "comb_matrices = []\n",
    "\n",
    "\n",
    "comb_fpr = []\n",
    "comb_tpr = []\n",
    "comb_thresh = []\n",
    "\n",
    "comb_auc = 0\n",
    "\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"])\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"])\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    comb_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    comb_ensemble.fit(x_train, y_train)\n",
    "    y_pred = comb_ensemble.predict(x_test)\n",
    "\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    comb_fpr.append(fpr)\n",
    "    comb_tpr.append(tpr)\n",
    "    comb_thresh.append(thresh)\n",
    "    comb_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    comb_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = comb_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "comb_output[\"test\"] = [(test_total / run_count)]\n",
    "comb_output[\"train\"] = [(train_total / run_count)]\n",
    "comb_output = pd.DataFrame(comb_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "comb_matrices = np.mean(np.array(comb_matrices), axis=0)\n",
    "print(comb_matrices)\n",
    "\n",
    "\n",
    "comb_fpr = np.mean(np.array(comb_fpr), axis=0)\n",
    "comb_tpr = np.mean(np.array(comb_tpr), axis=0)\n",
    "comb_thresh = np.mean(np.array(comb_thresh), axis=0)\n",
    "\n",
    "comb_auc = comb_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "comb_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    POLARITY\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "pol_output = {\"train\" : None, \"test\" : None}\n",
    "pol_matrices = []\n",
    "\n",
    "\n",
    "pol_fpr = []\n",
    "pol_tpr = []\n",
    "pol_thresh = []\n",
    "\n",
    "pol_auc = 0\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "  \n",
    "    x_train = x.iloc[train_index]\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    x_test = x.iloc[test_index]\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    pol_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    pol_ensemble.fit(x_train, y_train)\n",
    "    y_pred = pol_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    pol_fpr.append(fpr)\n",
    "    pol_tpr.append(tpr)\n",
    "    pol_thresh.append(thresh)\n",
    "    pol_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "    pol_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = pol_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "pol_output[\"test\"] = [(test_total / run_count)]\n",
    "pol_output[\"train\"] = [(train_total / run_count)]\n",
    "pol_output = pd.DataFrame(pol_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "pol_matrices = np.mean(np.array(pol_matrices), axis=0)\n",
    "print(pol_matrices)\n",
    "\n",
    "pol_fpr = np.mean(np.array(pol_fpr), axis=0)\n",
    "pol_tpr = np.mean(np.array(pol_tpr), axis=0)\n",
    "pol_thresh = np.mean(np.array(pol_thresh), axis=0)\n",
    "\n",
    "pol_auc = pol_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pol_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    TF-IDF\n",
    "'''\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# average accuracies\n",
    "tf_output = {\"train\" : None, \"test\" : None}\n",
    "tf_matrices = []\n",
    "\n",
    "train_total = 0\n",
    "test_total = 0\n",
    "run_count = 0\n",
    "\n",
    "tf_fpr = []\n",
    "tf_tpr = []\n",
    "tf_thresh = []\n",
    "\n",
    "tf_auc = 0\n",
    "\n",
    "#lbgfs\n",
    "x = features\n",
    "y = classes\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(i)\n",
    "    scaler = StandardScaler()\n",
    "    print(\"tf_idf training\")\n",
    "    x_train = add_tf_idf_vector(x.iloc[train_index], filtered[\"corpus\"].iloc[train_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    print(\"tf_idf testing\")\n",
    "    x_test = add_tf_idf_vector(x.iloc[test_index], filtered[\"corpus\"].iloc[test_index], filtered[\"corpus\"]).drop(features, axis=1)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    tf_ensemble = VotingClassifier(estimators=[\n",
    "    ('lr', LogisticRegression(max_iter=500)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "    ], voting='soft')\n",
    "    print(\"ensemble fitting\")\n",
    "    tf_ensemble.fit(x_train, y_train)\n",
    "    y_pred = tf_ensemble.predict(x_test)\n",
    "    fpr, tpr, thresh = metrics.roc_curve(y_test, y_pred, pos_label=1)\n",
    "    tf_fpr.append(fpr)\n",
    "    tf_tpr.append(tpr)\n",
    "    tf_thresh.append(thresh)\n",
    "    tf_auc += metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    tf_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    test_total += accuracy_score(y_test, y_pred)\n",
    "\n",
    "    y_train_pred = tf_ensemble.predict(x_train)\n",
    "    train_total += accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "    run_count += 1\n",
    "\n",
    "print(f\"Train accuracy on {folds}-fold cross-validation: {train_total / float(run_count)}\")\n",
    "print(f\"Test accuracy on {folds}-fold cross-validation: {test_total / float(run_count)}\")\n",
    "\n",
    "tf_output[\"test\"] = [(test_total / run_count)]\n",
    "tf_output[\"train\"] = [(train_total / run_count)]\n",
    "tf_output = pd.DataFrame(tf_output)\n",
    "\n",
    "print(\"Average confusion matrix:\")\n",
    "tf_matrices = np.mean(np.array(tf_matrices), axis=0)\n",
    "print(tf_matrices)\n",
    "\n",
    "tf_fpr = np.mean(np.array(tf_fpr), axis=0)\n",
    "tf_tpr = np.mean(np.array(tf_tpr), axis=0)\n",
    "tf_thresh = np.mean(np.array(tf_thresh), axis=0)\n",
    "\n",
    "tf_auc = tf_auc / float(run_count)\n",
    "\n",
    "\n",
    "\n",
    "tf_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    combine accuracies into one table\n",
    "'''\n",
    "\n",
    "final_results = pd.concat((pol_output, tf_output, comb_output), axis=0)\n",
    "final_results.index = [\"Polarity\", \"Tf-Idf\", \"Polarity + Tf-Idf\"]\n",
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finally, save accuracy metrics to the spreadsheet\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "writer = pd.ExcelWriter(EXCEL_FILE, engine=\"openpyxl\")\n",
    "writer.book = book\n",
    "final_results.to_excel(writer, sheet_name=f\"accuracies\")\n",
    "book.save(filename=EXCEL_FILE)\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl.drawing\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(pol_fpr, pol_tpr,\n",
    " lw=lw, label='Polarity: (%0.2f)' % pol_auc)\n",
    "plt.plot(tf_fpr, tf_tpr,\n",
    " lw=lw, label='Tf-Idf: (%0.2f)' % tf_auc)\n",
    "plt.plot(comb_fpr, comb_tpr,\n",
    " lw=lw, label='Polarity + Tf-Idf: (%0.2f)' % comb_auc)\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# save figure as PNG\n",
    "png = io.BytesIO()\n",
    "plt.savefig(png, format=\"png\")\n",
    "\n",
    "\n",
    "# write PNG to excel file\n",
    "book = load_workbook(EXCEL_FILE)\n",
    "ws = book.active\n",
    "\n",
    "img = openpyxl.drawing.image.Image(png)\n",
    "img.anchor = \"A1\"\n",
    "ws.add_image(img)\n",
    "book.save(filename=EXCEL_FILE)\n",
    "plt.close()\n",
    "book.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
